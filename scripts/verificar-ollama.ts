/**
 * ü§ñ VERIFICAR OLLAMA
 * Verifica que Ollama est√© corriendo y el modelo gemma:2b est√© disponible
 */

// Forzar recarga del .env
import { config } from 'dotenv';
config({ override: true });

import { OllamaService } from '../src/lib/ollama-service';

async function verificarOllama() {
  console.log('ü§ñ VERIFICACI√ìN DE OLLAMA\n');

  try {
    // 1. Verificar si Ollama est√° disponible
    console.log('1Ô∏è‚É£ Verificando si Ollama est√° corriendo...');
    const available = await OllamaService.isAvailable();
    
    if (!available) {
      console.log('‚ùå Ollama NO est√° disponible\n');
      console.log('üìù Para iniciar Ollama:');
      console.log('   1. Abre una nueva terminal');
      console.log('   2. Ejecuta: ollama serve');
      console.log('   3. Deja esa terminal abierta\n');
      return;
    }

    console.log('‚úÖ Ollama est√° corriendo\n');

    // 2. Listar modelos disponibles
    console.log('2Ô∏è‚É£ Modelos disponibles:');
    const models = await OllamaService.listModels();
    
    if (models.length === 0) {
      console.log('   ‚ö†Ô∏è No hay modelos descargados\n');
    } else {
      models.forEach(model => {
        console.log(`   - ${model}`);
      });
      console.log('');
    }

    // 3. Verificar modelo gemma:2b
    console.log('3Ô∏è‚É£ Verificando modelo gemma:2b...');
    const hasGemma = await OllamaService.checkModel();
    
    if (!hasGemma) {
      console.log('‚ùå Modelo gemma:2b NO encontrado\n');
      console.log('üìù Para descargar gemma:2b:');
      console.log('   ollama pull gemma:2b\n');
      console.log('üí° Este modelo es peque√±o (~1.4GB) y r√°pido');
      console.log('üí° Perfecto para entrenamiento local ilimitado\n');
      return;
    }

    console.log('‚úÖ Modelo gemma:2b disponible\n');

    // 4. Obtener informaci√≥n del modelo
    console.log('4Ô∏è‚É£ Informaci√≥n del modelo:');
    const info = await OllamaService.getModelInfo();
    
    if (info) {
      console.log(`   Modelo: ${info.modelfile || 'gemma:2b'}`);
      console.log(`   Tama√±o: ${info.size ? (info.size / 1024 / 1024 / 1024).toFixed(2) + ' GB' : 'N/A'}`);
    }
    console.log('');

    // 5. Probar generaci√≥n de respuesta
    console.log('5Ô∏è‚É£ Probando generaci√≥n de respuesta...');
    const testResponse = await OllamaService.generateResponse({
      systemPrompt: 'Eres un asistente de ventas amigable.',
      messages: [
        { role: 'user', content: 'Hola, tienes el curso de piano?' }
      ]
    });

    if (testResponse) {
      console.log('‚úÖ Respuesta generada exitosamente:');
      console.log(`   "${testResponse.text.substring(0, 150)}..."`);
      console.log(`   Confianza: ${(testResponse.confidence * 100).toFixed(0)}%\n`);
    } else {
      console.log('‚ùå No se pudo generar respuesta\n');
    }

    // 6. Resumen
    console.log('='.repeat(60));
    console.log('üìä RESUMEN\n');
    console.log('‚úÖ Ollama est√° listo para usar');
    console.log('‚úÖ Modelo gemma:2b disponible');
    console.log('‚úÖ Generaci√≥n de respuestas funciona');
    console.log('\nüí° Ahora puedes entrenar el bot SIN L√çMITES:');
    console.log('   npx tsx scripts/entrenar-bot-automatico.ts');
    console.log('   npx tsx scripts/entrenar-conversaciones-completas.ts\n');
    console.log('üöÄ Ollama usar√° tu CPU/GPU local (gratis e ilimitado)');
    console.log('üîÑ Groq se usar√° solo como respaldo si Ollama falla\n');

  } catch (error) {
    console.error('‚ùå Error:', error);
  }
}

verificarOllama();

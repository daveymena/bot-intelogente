/**
 * ğŸ§ª TEST COMPLETO DE OLLAMA
 * Prueba velocidad, respuesta y timeout
 */

async function testOllama() {
  console.log('ğŸ§ª TEST DE OLLAMA\n')
  console.log('=' .repeat(60))

  const ollamaUrl = process.env.OLLAMA_BASE_URL || 'https://bot-whatsapp-ollama.sqaoeo.easypanel.host'
  const ollamaModel = process.env.OLLAMA_MODEL || 'gemma:2b'
  const timeout = 60000 // 60 segundos

  console.log(`\nğŸ“ URL: ${ollamaUrl}`)
  console.log(`ğŸ¤– Modelo: ${ollamaModel}`)
  console.log(`â±ï¸  Timeout: ${timeout / 1000}s\n`)

  // Test 1: Verificar que el servidor responde
  console.log('1ï¸âƒ£ Verificando conexiÃ³n...')
  const startPing = Date.now()
  
  try {
    const pingResponse = await fetch(`${ollamaUrl}/api/tags`)
    const pingTime = Date.now() - startPing
    
    if (pingResponse.ok) {
      console.log(`   âœ… Servidor responde en ${pingTime}ms`)
      const data = await pingResponse.json()
      console.log(`   ğŸ“¦ Modelos disponibles: ${data.models?.length || 0}`)
      data.models?.forEach((m: any) => {
        console.log(`      - ${m.name}`)
      })
    } else {
      console.log(`   âŒ Error: ${pingResponse.status}`)
      return
    }
  } catch (error: any) {
    console.log(`   âŒ Error de conexiÃ³n: ${error.message}`)
    return
  }

  // Test 2: Mensaje corto (deberÃ­a ser rÃ¡pido)
  console.log('\n2ï¸âƒ£ Test con mensaje CORTO...')
  const shortMessage = 'Hola, Â¿cÃ³mo estÃ¡s?'
  console.log(`   ğŸ“ Mensaje: "${shortMessage}"`)
  
  const startShort = Date.now()
  
  try {
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), timeout)

    const response = await fetch(`${ollamaUrl}/api/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: ollamaModel,
        messages: [
          { role: 'user', content: shortMessage }
        ],
        stream: false
      }),
      signal: controller.signal
    })

    clearTimeout(timeoutId)
    const shortTime = Date.now() - startShort

    if (response.ok) {
      const data = await response.json()
      const content = data.message?.content || 'Sin respuesta'
      
      console.log(`   âœ… Respuesta en ${shortTime}ms (${(shortTime / 1000).toFixed(1)}s)`)
      console.log(`   ğŸ’¬ Respuesta: "${content.substring(0, 100)}${content.length > 100 ? '...' : ''}"`)
      
      if (shortTime > 30000) {
        console.log(`   âš ï¸  ADVERTENCIA: Respuesta lenta (>30s)`)
      }
    } else {
      console.log(`   âŒ Error: ${response.status}`)
    }
  } catch (error: any) {
    const shortTime = Date.now() - startShort
    if (error.name === 'AbortError') {
      console.log(`   âŒ TIMEOUT despuÃ©s de ${shortTime}ms`)
    } else {
      console.log(`   âŒ Error: ${error.message}`)
    }
  }

  // Test 3: Mensaje con contexto (simula conversaciÃ³n real)
  console.log('\n3ï¸âƒ£ Test con CONTEXTO (conversaciÃ³n)...')
  
  const conversationMessages = [
    { role: 'system', content: 'Eres un asistente de ventas amigable de Tecnovariedades D&S.' },
    { role: 'user', content: 'Hola' },
    { role: 'assistant', content: 'Â¡Hola! Bienvenido a Tecnovariedades D&S. Â¿En quÃ© puedo ayudarte?' },
    { role: 'user', content: 'Busco una laptop' }
  ]
  
  console.log(`   ğŸ“ Mensajes en contexto: ${conversationMessages.length}`)
  
  const startContext = Date.now()
  
  try {
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), timeout)

    const response = await fetch(`${ollamaUrl}/api/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: ollamaModel,
        messages: conversationMessages,
        stream: false
      }),
      signal: controller.signal
    })

    clearTimeout(timeoutId)
    const contextTime = Date.now() - startContext

    if (response.ok) {
      const data = await response.json()
      const content = data.message?.content || 'Sin respuesta'
      
      console.log(`   âœ… Respuesta en ${contextTime}ms (${(contextTime / 1000).toFixed(1)}s)`)
      console.log(`   ğŸ’¬ Respuesta: "${content.substring(0, 150)}${content.length > 150 ? '...' : ''}"`)
      
      if (contextTime > 45000) {
        console.log(`   âš ï¸  ADVERTENCIA: Respuesta muy lenta (>45s)`)
      }
    } else {
      console.log(`   âŒ Error: ${response.status}`)
    }
  } catch (error: any) {
    const contextTime = Date.now() - startContext
    if (error.name === 'AbortError') {
      console.log(`   âŒ TIMEOUT despuÃ©s de ${contextTime}ms`)
      console.log(`   ğŸ’¡ Sugerencia: Aumentar OLLAMA_TIMEOUT en .env`)
    } else {
      console.log(`   âŒ Error: ${error.message}`)
    }
  }

  // Test 4: Mensaje largo (peor caso)
  console.log('\n4ï¸âƒ£ Test con mensaje LARGO (peor caso)...')
  
  const longContext = [
    { role: 'system', content: 'Eres un asistente de ventas.' },
    ...Array(10).fill(null).map((_, i) => [
      { role: 'user', content: `Pregunta ${i + 1} sobre productos` },
      { role: 'assistant', content: `Respuesta detallada ${i + 1} con informaciÃ³n sobre productos disponibles` }
    ]).flat()
  ]
  
  console.log(`   ğŸ“ Mensajes en contexto: ${longContext.length}`)
  
  const startLong = Date.now()
  
  try {
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), timeout)

    const response = await fetch(`${ollamaUrl}/api/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: ollamaModel,
        messages: longContext,
        stream: false
      }),
      signal: controller.signal
    })

    clearTimeout(timeoutId)
    const longTime = Date.now() - startLong

    if (response.ok) {
      const data = await response.json()
      const content = data.message?.content || 'Sin respuesta'
      
      console.log(`   âœ… Respuesta en ${longTime}ms (${(longTime / 1000).toFixed(1)}s)`)
      console.log(`   ğŸ’¬ Respuesta: "${content.substring(0, 100)}${content.length > 100 ? '...' : ''}"`)
      
      if (longTime > 60000) {
        console.log(`   âš ï¸  ADVERTENCIA: Excede timeout recomendado`)
      }
    } else {
      console.log(`   âŒ Error: ${response.status}`)
    }
  } catch (error: any) {
    const longTime = Date.now() - startLong
    if (error.name === 'AbortError') {
      console.log(`   âŒ TIMEOUT despuÃ©s de ${longTime}ms`)
      console.log(`   ğŸ’¡ Sugerencia: Reducir historial de conversaciÃ³n`)
    } else {
      console.log(`   âŒ Error: ${error.message}`)
    }
  }

  // Resumen
  console.log('\n' + '='.repeat(60))
  console.log('ğŸ“Š RESUMEN')
  console.log('='.repeat(60))
  console.log('\nâœ… Tests completados')
  console.log('\nğŸ’¡ Recomendaciones:')
  console.log('   - Mensaje corto: < 10s âœ…')
  console.log('   - Con contexto: < 30s âœ…')
  console.log('   - Mensaje largo: < 60s âš ï¸')
  console.log('\nğŸ“ Si hay timeouts frecuentes:')
  console.log('   1. Aumentar OLLAMA_TIMEOUT=90000 en .env')
  console.log('   2. Reducir historial a 10-15 mensajes')
  console.log('   3. Considerar modelo mÃ¡s rÃ¡pido (tinyllama)')
}

// Ejecutar test
testOllama()
  .then(() => {
    console.log('\nâœ… Test completado')
    process.exit(0)
  })
  .catch((error) => {
    console.error('\nâŒ Error en test:', error)
    process.exit(1)
  })

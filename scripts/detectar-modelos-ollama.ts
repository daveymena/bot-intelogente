/**
 * üîç DETECTAR MODELOS DISPONIBLES EN OLLAMA
 * 
 * Detecta qu√© modelos est√°n instalados y sugiere el mejor
 */

interface OllamaModel {
  name: string
  size: number
  modified_at: string
}

interface ModelRecommendation {
  name: string
  speed: string
  quality: string
  recommended: boolean
  reason: string
}

async function detectarModelos() {
  console.log('üîç DETECTANDO MODELOS EN OLLAMA\n')
  console.log('=' .repeat(60))

  const ollamaUrl = process.env.OLLAMA_URL || 'https://davey-ollama2.mapf5v.easypanel.host'

  console.log(`\nüìç URL: ${ollamaUrl}\n`)

  // 1Ô∏è‚É£ Obtener modelos disponibles
  console.log('1Ô∏è‚É£ CONSULTANDO MODELOS DISPONIBLES...\n')

  try {
    const response = await fetch(`${ollamaUrl}/api/tags`, {
      signal: AbortSignal.timeout(5000)
    })

    if (!response.ok) {
      console.error(`‚ùå Error HTTP: ${response.status} ${response.statusText}`)
      console.log('\nüí° SOLUCI√ìN:')
      console.log('   - Verifica que Ollama est√© corriendo en Easypanel')
      console.log('   - Verifica la URL en .env')
      return
    }

    const data = await response.json()

    if (!data.models || data.models.length === 0) {
      console.log('‚ö†Ô∏è NO HAY MODELOS INSTALADOS\n')
      console.log('üí° INSTALAR MODELOS RECOMENDADOS:')
      console.log('   ollama pull llama3.2:3b    # Recomendado (r√°pido y bueno)')
      console.log('   ollama pull gemma2:2b      # Alternativa (muy r√°pido)')
      console.log('   ollama pull mistral:7b     # Alta calidad (m√°s lento)')
      return
    }

    console.log(`‚úÖ Encontrados ${data.models.length} modelos:\n`)

    // Mostrar modelos disponibles
    data.models.forEach((model: OllamaModel, index: number) => {
      const sizeGB = (model.size / 1024 / 1024 / 1024).toFixed(2)
      console.log(`${index + 1}. ${model.name}`)
      console.log(`   Tama√±o: ${sizeGB} GB`)
      console.log(`   Modificado: ${new Date(model.modified_at).toLocaleString('es-CO')}`)
      console.log()
    })

    // 2Ô∏è‚É£ Analizar y recomendar
    console.log('2Ô∏è‚É£ AN√ÅLISIS Y RECOMENDACIONES...\n')

    const recommendations: ModelRecommendation[] = []

    // Analizar cada modelo
    for (const model of data.models) {
      const modelName = model.name.toLowerCase()
      
      // Llama 3.2
      if (modelName.includes('llama3.2')) {
        if (modelName.includes('3b')) {
          recommendations.push({
            name: model.name,
            speed: '‚ö°‚ö°‚ö°‚ö°',
            quality: '‚≠ê‚≠ê‚≠ê‚≠ê',
            recommended: true,
            reason: 'Excelente balance velocidad/calidad'
          })
        } else if (modelName.includes('1b')) {
          recommendations.push({
            name: model.name,
            speed: '‚ö°‚ö°‚ö°‚ö°‚ö°',
            quality: '‚≠ê‚≠ê‚≠ê',
            recommended: false,
            reason: 'Muy r√°pido pero calidad limitada'
          })
        }
      }
      
      // Gemma 2
      else if (modelName.includes('gemma2')) {
        if (modelName.includes('2b')) {
          recommendations.push({
            name: model.name,
            speed: '‚ö°‚ö°‚ö°‚ö°‚ö°',
            quality: '‚≠ê‚≠ê‚≠ê',
            recommended: true,
            reason: 'Muy r√°pido para respuestas simples'
          })
        } else if (modelName.includes('9b')) {
          recommendations.push({
            name: model.name,
            speed: '‚ö°‚ö°',
            quality: '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê',
            recommended: false,
            reason: 'Alta calidad pero lento'
          })
        }
      }
      
      // Mistral
      else if (modelName.includes('mistral')) {
        if (modelName.includes('7b')) {
          recommendations.push({
            name: model.name,
            speed: '‚ö°‚ö°‚ö°',
            quality: '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê',
            recommended: true,
            reason: 'Excelente calidad, velocidad aceptable'
          })
        }
      }
      
      // Llama 3
      else if (modelName.includes('llama3') && !modelName.includes('llama3.2')) {
        if (modelName.includes('8b')) {
          recommendations.push({
            name: model.name,
            speed: '‚ö°‚ö°‚ö°',
            quality: '‚≠ê‚≠ê‚≠ê‚≠ê',
            recommended: true,
            reason: 'Buena calidad, velocidad moderada'
          })
        }
      }
      
      // Otros modelos
      else {
        recommendations.push({
          name: model.name,
          speed: '‚ö°‚ö°',
          quality: '‚≠ê‚≠ê‚≠ê',
          recommended: false,
          reason: 'Modelo gen√©rico'
        })
      }
    }

    // Mostrar recomendaciones
    console.log('üìä AN√ÅLISIS DE MODELOS:\n')

    recommendations.forEach((rec, index) => {
      const icon = rec.recommended ? '‚úÖ' : '‚ö™'
      console.log(`${icon} ${rec.name}`)
      console.log(`   Velocidad: ${rec.speed}`)
      console.log(`   Calidad: ${rec.quality}`)
      console.log(`   ${rec.reason}`)
      console.log()
    })

    // 3Ô∏è‚É£ Sugerencia final
    console.log('3Ô∏è‚É£ CONFIGURACI√ìN RECOMENDADA...\n')

    const recommended = recommendations.filter(r => r.recommended)

    if (recommended.length === 0) {
      console.log('‚ö†Ô∏è No hay modelos recomendados instalados\n')
      console.log('üí° INSTALAR MODELOS RECOMENDADOS:')
      console.log('   ollama pull llama3.2:3b')
      console.log('   ollama pull gemma2:2b')
      return
    }

    // Encontrar el mejor modelo principal
    const mainModel = recommended.find(r => 
      r.name.includes('llama3.2:3b') || 
      r.name.includes('mistral:7b') ||
      r.name.includes('llama3:8b')
    ) || recommended[0]

    // Encontrar el mejor modelo r√°pido
    const fastModel = recommended.find(r => 
      r.name.includes('gemma2:2b') ||
      r.name.includes('llama3.2:1b')
    ) || recommended[0]

    console.log('‚úÖ CONFIGURACI√ìN SUGERIDA PARA .env:\n')
    console.log(`OLLAMA_MODEL=${mainModel.name}`)
    console.log(`OLLAMA_MODEL_FAST=${fastModel.name}`)
    console.log()

    console.log('üìù COPIAR ESTO A .env:')
    console.log('‚îÄ'.repeat(60))
    console.log(`OLLAMA_URL=${ollamaUrl}`)
    console.log(`OLLAMA_MODEL=${mainModel.name}`)
    console.log(`OLLAMA_MODEL_FAST=${fastModel.name}`)
    console.log(`OLLAMA_TIMEOUT=45000`)
    console.log('‚îÄ'.repeat(60))

    // 4Ô∏è‚É£ Probar modelo recomendado
    console.log('\n4Ô∏è‚É£ PROBANDO MODELO RECOMENDADO...\n')

    try {
      console.log(`üß™ Probando: ${mainModel.name}`)
      console.log('‚è≥ Generando respuesta...\n')

      const startTime = Date.now()

      const testResponse = await fetch(`${ollamaUrl}/api/generate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: mainModel.name,
          prompt: 'Responde en una palabra: ¬øCu√°l es la capital de Colombia?',
          stream: false,
          options: {
            temperature: 0.7,
            num_predict: 50
          }
        }),
        signal: AbortSignal.timeout(30000)
      })

      const duration = Date.now() - startTime

      if (!testResponse.ok) {
        console.error(`‚ùå Error: ${testResponse.status}`)
        return
      }

      const testData = await testResponse.json()

      console.log(`‚úÖ Respuesta en ${duration}ms:`)
      console.log(`   "${testData.response.trim()}"`)
      console.log()

      if (testData.response.toLowerCase().includes('bogot√°') || 
          testData.response.toLowerCase().includes('bogota')) {
        console.log('‚úÖ Respuesta correcta! El modelo funciona perfectamente.')
      } else {
        console.log('‚ö†Ô∏è Respuesta inesperada, pero el modelo est√° funcionando.')
      }

    } catch (error: any) {
      console.error(`‚ùå Error probando modelo: ${error.message}`)
    }

  } catch (error: any) {
    console.error(`‚ùå Error: ${error.message}`)
    console.log('\nüí° SOLUCI√ìN:')
    console.log('   - Verifica que Ollama est√© corriendo')
    console.log('   - Verifica la URL en .env')
  }

  console.log('\n' + '='.repeat(60))
  console.log('‚úÖ DETECCI√ìN COMPLETADA')
  console.log('='.repeat(60))
}

// Ejecutar
detectarModelos()
  .then(() => {
    console.log('\n‚úÖ Script finalizado')
    process.exit(0)
  })
  .catch((error) => {
    console.error('\n‚ùå Error:', error)
    process.exit(1)
  })

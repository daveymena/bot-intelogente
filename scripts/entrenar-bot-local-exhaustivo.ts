/**
 * üéì SCRIPT DE ENTRENAMIENTO EXHAUSTIVO
 * 
 * Este script usa Groq y Ollama para generar miles de conversaciones
 * y entrenar al bot local para que funcione sin IA externa.
 * 
 * Uso:
 * npm run train:exhaustive
 */

import { PrismaClient } from '@prisma/client';
import { HybridLearningSystem } from '../src/lib/hybrid-learning-system';
import { GroqService } from '../src/lib/groq-service';
import { OllamaService } from '../src/lib/ollama-service';

const prisma = new PrismaClient();

// Escenarios de conversaci√≥n a generar
const TRAINING_SCENARIOS = [
  // Ventas
  { type: 'greeting', count: 100, description: 'Saludos iniciales' },
  { type: 'product_search', count: 500, description: 'B√∫squeda de productos' },
  { type: 'price_inquiry', count: 300, description: 'Preguntas sobre precios' },
  { type: 'photo_request', count: 200, description: 'Solicitud de fotos' },
  { type: 'product_details', count: 300, description: 'Detalles de productos' },
  { type: 'availability', count: 200, description: 'Disponibilidad y stock' },
  { type: 'payment_method', count: 250, description: 'M√©todos de pago' },
  { type: 'purchase_intent', count: 200, description: 'Intenci√≥n de compra' },
  { type: 'shipping', count: 150, description: 'Env√≠os y entregas' },
  
  // Objeciones
  { type: 'price_objection', count: 150, description: 'Objeciones de precio' },
  { type: 'quality_concern', count: 100, description: 'Dudas de calidad' },
  { type: 'comparison', count: 100, description: 'Comparaciones' },
  
  // Soporte
  { type: 'general_inquiry', count: 200, description: 'Consultas generales' },
  { type: 'farewell', count: 100, description: 'Despedidas' },
];

async function generateTrainingData() {
  console.log('üéì INICIANDO ENTRENAMIENTO EXHAUSTIVO\n');
  console.log('‚ïê'.repeat(60));
  
  let totalGenerated = 0;
  let totalLearned = 0;
  
  // Obtener productos para contexto
  const products = await prisma.product.findMany({
    where: { status: 'AVAILABLE' },
    take: 50 // Primeros 50 productos
  });
  
  console.log(`\nüì¶ Productos disponibles: ${products.length}`);
  console.log('ü§ñ Generando conversaciones con Groq/Ollama...\n');
  
  for (const scenario of TRAINING_SCENARIOS) {
    console.log(`\n${'‚îÄ'.repeat(60)}`);
    console.log(`üìù Escenario: ${scenario.description}`);
    console.log(`üéØ Objetivo: ${scenario.count} conversaciones`);
    console.log(`${'‚îÄ'.repeat(60)}\n`);
    
    for (let i = 0; i < scenario.count; i++) {
      try {
        // Seleccionar producto aleatorio
        const product = products[Math.floor(Math.random() * products.length)];
        
        // Generar pregunta del usuario usando Groq
        const userQuery = await generateUserQuery(scenario.type, product);
        
        if (!userQuery) continue;
        
        // Procesar con sistema h√≠brido (esto generar√° la respuesta con IA y la guardar√°)
        const response = await HybridLearningSystem.processWithLearning({
          message: userQuery,
          context: {
            currentProduct: product,
            messages: []
          },
          productId: product.id
        });
        
        if (response.learned) {
          totalLearned++;
        }
        
        totalGenerated++;
        
        // Mostrar progreso cada 10 conversaciones
        if ((i + 1) % 10 === 0) {
          console.log(`  ‚úÖ Progreso: ${i + 1}/${scenario.count} (${totalLearned} aprendidas)`);
        }
        
        // Peque√±a pausa para no saturar las APIs
        await new Promise(resolve => setTimeout(resolve, 100));
        
      } catch (error) {
        console.error(`  ‚ùå Error en conversaci√≥n ${i + 1}:`, error.message);
      }
    }
    
    console.log(`\n‚úÖ Escenario completado: ${scenario.description}`);
  }
  
  // Resumen final
  console.log('\n\n');
  console.log('‚ïê'.repeat(60));
  console.log('üìä RESUMEN DEL ENTRENAMIENTO');
  console.log('‚ïê'.repeat(60));
  console.log(`\n‚úÖ Conversaciones generadas: ${totalGenerated}`);
  console.log(`üß† Patrones aprendidos: ${totalLearned}`);
  
  // Estad√≠sticas de la base de conocimiento
  const stats = await HybridLearningSystem.getLearningStats();
  console.log(`\nüìö Base de Conocimiento:`);
  console.log(`   Total de entradas: ${stats.totalKnowledge}`);
  console.log(`   Patrones √∫nicos: ${stats.totalPatterns}`);
  console.log(`   Confianza promedio: ${(stats.avgConfidence * 100).toFixed(1)}%`);
  console.log(`   Aprendizaje reciente: ${stats.learningRate}`);
  
  console.log('\n‚úÖ ENTRENAMIENTO COMPLETADO\n');
  console.log('El bot ahora puede funcionar sin IA externa en la mayor√≠a de casos.\n');
}

/**
 * Genera una pregunta de usuario realista usando Groq
 */
async function generateUserQuery(scenarioType: string, product: any): Promise<string | null> {
  const prompts: Record<string, string> = {
    greeting: `Genera un saludo corto y natural de un cliente en espa√±ol (m√°ximo 10 palabras). Ejemplos: "Hola", "Buenos d√≠as", "Hola, c√≥mo est√°s"`,
    
    product_search: `Genera una pregunta de un cliente buscando el producto "${product.name}" de forma natural. Var√≠a el estilo: directo, con contexto, con presupuesto, etc. Solo la pregunta, sin respuesta.`,
    
    price_inquiry: `Genera una pregunta sobre el precio del producto "${product.name}". Var√≠a: "cu√°nto cuesta", "qu√© precio tiene", "cu√°l es el valor", etc.`,
    
    photo_request: `Genera una solicitud de foto del producto "${product.name}". Var√≠a: "tienes foto", "mu√©strame", "c√≥mo se ve", etc.`,
    
    product_details: `Genera una pregunta sobre caracter√≠sticas del producto "${product.name}". Pregunta por especificaciones, detalles, qu√© incluye, etc.`,
    
    availability: `Genera una pregunta sobre disponibilidad del producto "${product.name}". Var√≠a: "tienes en stock", "hay disponible", "cu√°ndo llega", etc.`,
    
    payment_method: `Genera una pregunta sobre m√©todos de pago. Var√≠a: "c√≥mo puedo pagar", "aceptan nequi", "formas de pago", etc.`,
    
    purchase_intent: `Genera una expresi√≥n de intenci√≥n de compra del producto "${product.name}". Var√≠a: "lo quiero", "me interesa", "c√≥mo lo compro", etc.`,
    
    shipping: `Genera una pregunta sobre env√≠o. Var√≠a: "hacen env√≠os", "cu√°nto demora", "env√≠an a mi ciudad", etc.`,
    
    price_objection: `Genera una objeci√≥n de precio sobre "${product.name}". Var√≠a: "est√° muy caro", "hay m√°s econ√≥mico", "descuento", etc.`,
    
    quality_concern: `Genera una duda sobre calidad. Var√≠a: "es original", "tiene garant√≠a", "es bueno", etc.`,
    
    comparison: `Genera una pregunta comparando productos. Menciona "${product.name}" y pregunta por alternativas.`,
    
    general_inquiry: `Genera una pregunta general sobre el negocio. Var√≠a: "horarios", "ubicaci√≥n", "contacto", etc.`,
    
    farewell: `Genera una despedida corta. Var√≠a: "gracias", "ok perfecto", "hasta luego", etc.`
  };
  
  const prompt = prompts[scenarioType] || prompts.general_inquiry;
  
  try {
    const response = await GroqService.generateResponse({
      systemPrompt: 'Eres un cliente colombiano buscando productos. Genera solo la pregunta, sin contexto adicional. M√°ximo 20 palabras.',
      messages: [{ role: 'user', content: prompt }]
    });
    
    return response?.text?.trim() || null;
  } catch (error) {
    // Si Groq falla, intentar con Ollama
    try {
      const response = await OllamaService.generateResponse({
        systemPrompt: 'Genera solo la pregunta del cliente, sin contexto. M√°ximo 20 palabras.',
        messages: [{ role: 'user', content: prompt }]
      });
      
      return response?.text?.trim() || null;
    } catch {
      return null;
    }
  }
}

// Ejecutar entrenamiento
generateTrainingData()
  .catch(console.error)
  .finally(() => prisma.$disconnect());

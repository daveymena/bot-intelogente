# âœ… CONFIGURACIÃ“N GROQ + OLLAMA COMPLETADA

## ğŸ¯ Estado Actual

Las IAs de Groq y Ollama estÃ¡n **ACTIVAS y CONFIGURADAS** correctamente.

## ğŸ”§ ConfiguraciÃ³n Aplicada

### Groq (Primario)
```env
GROQ_API_KEY=tu_groq_api_key_aqui
GROQ_API_KEY_2=tu_groq_api_key_2_aqui
GROQ_API_KEY_6=tu_groq_api_key_6_aqui
GROQ_ENABLED=true
GROQ_MODEL=llama-3.1-8b-instant
GROQ_MAX_TOKENS=300
GROQ_TIMEOUT=60000
```

**CaracterÃ­sticas:**
- âœ… 3 API keys configuradas
- âœ… RotaciÃ³n automÃ¡tica cuando se alcanza el lÃ­mite
- âœ… Modelo rÃ¡pido: llama-3.1-8b-instant
- âœ… LÃ­mite de tokens: 300 (respuestas concisas)

### Ollama (Fallback)
```env
OLLAMA_ENABLED=true
OLLAMA_BASE_URL=https://bot-whatsapp-ollama.sqaoeo.easypanel.host
OLLAMA_MODEL=gemma:2b
OLLAMA_TIMEOUT=60000
OLLAMA_MAX_TOKENS=500
```

**CaracterÃ­sticas:**
- âœ… Activado como fallback
- âœ… Servidor en Easypanel
- âœ… Modelo ligero: gemma:2b
- âœ… Timeout de 60 segundos

### Sistema de Fallback
```env
AI_PROVIDER=groq
DEFAULT_AI_PROVIDER=groq
AI_FALLBACK_ENABLED=true
AI_USE_REASONING=true
```

## ğŸ”„ Flujo de Respuesta

```
1. GROQ (Primario)
   â”œâ”€ API Key 1 â†’ Si falla por rate limit
   â”œâ”€ API Key 2 â†’ Si falla por rate limit
   â””â”€ API Key 3 â†’ Si falla por rate limit
        â†“
2. OLLAMA (Fallback)
   â””â”€ Si Groq agota todas las keys
        â†“
3. RESPUESTA ESTÃTICA (Emergencia)
   â””â”€ Si Ollama tambiÃ©n falla
```

## ğŸš€ Mejoras Implementadas

### 1. RotaciÃ³n AutomÃ¡tica de API Keys
```typescript
// El sistema rota automÃ¡ticamente entre 3 API keys de Groq
const GROQ_API_KEYS = [
  process.env.GROQ_API_KEY,
  process.env.GROQ_API_KEY_2,
  process.env.GROQ_API_KEY_6,
];

// Cuando una key alcanza el lÃ­mite, rota a la siguiente
function rotateApiKey() {
  currentKeyIndex = (currentKeyIndex + 1) % GROQ_API_KEYS.length;
}
```

### 2. Fallback Inteligente
```typescript
// Intenta Groq â†’ Ollama â†’ EstÃ¡tico
export async function sendWithFallback(messages, options) {
  try {
    return await sendToGroq(messages, options); // Primario
  } catch (groqError) {
    try {
      return await sendToOllama(messages, options); // Fallback
    } catch (ollamaError) {
      return { content: 'Respuesta de emergencia' }; // EstÃ¡tico
    }
  }
}
```

### 3. Timeouts Configurables
- Groq: 60 segundos
- Ollama: 60 segundos
- Previene bloqueos indefinidos

### 4. Logs Detallados
```
[GroqClient] âœ… Respuesta exitosa con API key 1
[GroqClient] âŒ Error con API key 1: rate_limit
[GroqClient] ğŸ”„ Rotando a API key 2
[OllamaClient] ğŸ”„ Intentando con Ollama...
[OllamaClient] âœ… Respuesta exitosa de Ollama
```

## ğŸ§ª Probar ConfiguraciÃ³n

### Ejecutar script de prueba
```bash
npx tsx scripts/test-groq-ollama.ts
```

Este script:
- âœ… Prueba Groq con las 3 API keys
- âœ… Prueba Ollama
- âœ… Prueba el sistema con fallback
- âœ… Muestra estadÃ­sticas de uso
- âœ… Verifica tiempos de respuesta

### Salida esperada
```
ğŸ§ª PRUEBA DE GROQ Y OLLAMA

1ï¸âƒ£ PROBANDO GROQ
   â€¢ API Keys disponibles: 3
   â€¢ API Key actual: ...owIB
   â€¢ Modelo: llama-3.1-8b-instant
   âœ… Groq respondiÃ³ exitosamente

2ï¸âƒ£ PROBANDO OLLAMA
   â€¢ Habilitado: true
   â€¢ URL: https://bot-whatsapp-ollama.sqaoeo.easypanel.host
   âœ… Ollama respondiÃ³ exitosamente

3ï¸âƒ£ PROBANDO SISTEMA CON FALLBACK
   â€¢ Fallback habilitado: SÃ­
   âœ… Sistema respondiÃ³ exitosamente

âœ… PRUEBA COMPLETADA
```

## ğŸ“Š Ventajas del Sistema

### 1. Alta Disponibilidad
- 3 API keys de Groq = 3x mÃ¡s requests
- Fallback a Ollama si Groq falla
- Respuesta de emergencia si todo falla

### 2. OptimizaciÃ³n de Costos
- Groq es gratuito (con lÃ­mites)
- Ollama es local/self-hosted (gratis)
- RotaciÃ³n automÃ¡tica maximiza uso gratuito

### 3. Velocidad
- Groq: ~500-1000ms (muy rÃ¡pido)
- Ollama: ~2000-5000ms (mÃ¡s lento pero funcional)
- Modelo ligero: llama-3.1-8b-instant

### 4. Resiliencia
- No hay punto Ãºnico de falla
- RotaciÃ³n automÃ¡tica
- Fallback automÃ¡tico
- Respuesta de emergencia

## ğŸ” Verificar Estado

### Ver API key actual
```typescript
import { getApiStats } from '@/conversational-module/ai/groqClient';

const stats = getApiStats();
console.log('API Key actual:', stats.currentKey);
console.log('Total keys:', stats.totalKeys);
console.log('Ãndice actual:', stats.currentKeyIndex);
```

### Ver logs en tiempo real
```bash
npm run dev | grep -E "\[GroqClient\]|\[OllamaClient\]|\[AI\]"
```

## âš™ï¸ Ajustar ConfiguraciÃ³n

### Cambiar modelo de Groq
```env
# MÃ¡s rÃ¡pido (recomendado)
GROQ_MODEL=llama-3.1-8b-instant

# MÃ¡s inteligente (mÃ¡s lento)
GROQ_MODEL=llama-3.1-70b-versatile

# Alternativa
GROQ_MODEL=gemma2-9b-it
```

### Cambiar lÃ­mite de tokens
```env
# Respuestas mÃ¡s cortas (mÃ¡s rÃ¡pido, mÃ¡s barato)
GROQ_MAX_TOKENS=200

# Respuestas mÃ¡s largas (mÃ¡s lento, mÃ¡s caro)
GROQ_MAX_TOKENS=500
```

### Desactivar Ollama
```env
# Si Ollama es muy lento o no funciona
OLLAMA_ENABLED=false
```

### Desactivar fallback
```env
# Solo usar Groq (no recomendado)
AI_FALLBACK_ENABLED=false
```

## ğŸš¨ Troubleshooting

### Error: "Todas las API keys de Groq agotadas"
**Causa:** Las 3 API keys alcanzaron el lÃ­mite de rate

**SoluciÃ³n:**
1. Esperar unos minutos (los lÃ­mites se resetean)
2. Ollama tomarÃ¡ el control automÃ¡ticamente
3. Agregar mÃ¡s API keys si es necesario

### Error: "Ollama estÃ¡ desactivado"
**Causa:** `OLLAMA_ENABLED=false` en .env

**SoluciÃ³n:**
```env
OLLAMA_ENABLED=true
```

### Error: "Ollama timeout"
**Causa:** Ollama es muy lento o no responde

**SoluciÃ³n:**
1. Aumentar timeout:
```env
OLLAMA_TIMEOUT=120000
```
2. O desactivar Ollama:
```env
OLLAMA_ENABLED=false
```

### Groq responde muy lento
**SoluciÃ³n:** Cambiar a modelo mÃ¡s rÃ¡pido
```env
GROQ_MODEL=llama-3.1-8b-instant
```

## ğŸ“ˆ Monitoreo

### Ver uso de tokens
```bash
# Los logs mostrarÃ¡n:
[GroqClient] âœ… Respuesta exitosa
   â€¢ Tokens prompt: 45
   â€¢ Tokens respuesta: 87
   â€¢ Tokens totales: 132
```

### Ver rotaciÃ³n de API keys
```bash
# Los logs mostrarÃ¡n:
[GroqClient] ğŸ”„ Rotando a API key 2/3
[GroqClient] ğŸ”„ Rotando a API key 3/3
[GroqClient] ğŸ”„ Rotando a API key 1/3
```

### Ver fallback en acciÃ³n
```bash
# Los logs mostrarÃ¡n:
[AI] ğŸš€ Usando Groq como proveedor primario...
[AI] âŒ Groq fallÃ³: rate_limit
[AI] ğŸ”„ Groq fallÃ³, intentando con Ollama...
[OllamaClient] âœ… Respuesta exitosa de Ollama
```

## âœ… Checklist de ConfiguraciÃ³n

- [x] Groq activado con 3 API keys
- [x] Ollama activado como fallback
- [x] RotaciÃ³n automÃ¡tica implementada
- [x] Fallback automÃ¡tico implementado
- [x] Timeouts configurados
- [x] Logs detallados
- [x] Script de prueba creado
- [x] DocumentaciÃ³n completa

## ğŸ‰ Resultado Final

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  âœ… GROQ + OLLAMA CONFIGURADOS                             â”‚
â”‚                                                             â”‚
â”‚  ğŸš€ Groq (primario)                                        â”‚
â”‚     â€¢ 3 API keys con rotaciÃ³n automÃ¡tica                   â”‚
â”‚     â€¢ Modelo: llama-3.1-8b-instant                         â”‚
â”‚     â€¢ LÃ­mite: 300 tokens                                   â”‚
â”‚                                                             â”‚
â”‚  ğŸ”„ Ollama (fallback)                                      â”‚
â”‚     â€¢ Servidor: Easypanel                                  â”‚
â”‚     â€¢ Modelo: gemma:2b                                     â”‚
â”‚     â€¢ Timeout: 60 segundos                                 â”‚
â”‚                                                             â”‚
â”‚  ğŸ¯ Sistema resiliente y confiable                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ PrÃ³ximo Paso

```bash
# Probar configuraciÃ³n
npx tsx scripts/test-groq-ollama.ts

# Integrar sistema conversacional
npx tsx scripts/integrar-sistema-conversacional.ts

# Reiniciar servidor
npm run dev
```

**Â¡Las IAs estÃ¡n listas para usar!** ğŸ¯âœ¨

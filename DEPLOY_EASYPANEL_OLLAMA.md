# ü¶ô Gu√≠a: Desplegar Bot con Ollama en Easypanel

## üéØ Ventajas de usar Ollama:

- ‚úÖ **100% Gratis** - Sin costos de API
- ‚úÖ **Sin l√≠mites** - Tokens ilimitados
- ‚úÖ **R√°pido** - Corre en tu VPS
- ‚úÖ **Privado** - Tus datos no salen del servidor
- ‚úÖ **M√∫ltiples modelos** - Llama, Mistral, Phi, etc.

---

## üìã Paso 1: Instalar Easypanel en tu VPS

```bash
# Conectarte por SSH
ssh usuario@tu-servidor

# Instalar Easypanel
curl -sSL https://get.easypanel.io | sh
```

Espera 2-3 minutos. Luego accede a:
```
http://tu-ip-del-servidor:3000
```

---

## ü¶ô Paso 2: Agregar Ollama en Easypanel

### 2.1 Crear Proyecto
1. Click en **"Create Project"**
2. Nombre: `whatsapp-bot`

### 2.2 Agregar Ollama
1. Click **"Add Service"** ‚Üí **"App"**
2. Nombre: `ollama`
3. **Source:** Docker Image
4. **Image:** `ollama/ollama:latest`
5. **Port:** `11434`

### 2.3 Configurar Volumen para Ollama
1. En la secci√≥n **"Mounts"**
2. Click **"Add Mount"**
3. **Path:** `/root/.ollama`
4. **Size:** 10 GB (para almacenar modelos)

### 2.4 Deploy Ollama
Click en **"Deploy"**

---

## üì• Paso 3: Descargar Modelo en Ollama

Una vez que Ollama est√© corriendo:

1. En Easypanel, ve al servicio **"ollama"**
2. Click en **"Terminal"** o **"Console"**
3. Ejecuta:

```bash
# Descargar Llama 3.2 (3B - R√°pido y ligero)
ollama pull llama3.2

# O si prefieres Llama 3.1 (8B - M√°s potente)
ollama pull llama3.1

# O Mistral (7B - Excelente para espa√±ol)
ollama pull mistral
```

**Recomendado para tu VPS (8GB RAM):**
- `llama3.2` (3B) - Usa ~2GB RAM, muy r√°pido
- `llama3.1` (8B) - Usa ~5GB RAM, m√°s inteligente
- `mistral` (7B) - Usa ~4GB RAM, excelente espa√±ol

---

## üóÑÔ∏è Paso 4: Agregar PostgreSQL

1. Click **"Add Service"** ‚Üí **"PostgreSQL"**
2. Nombre: `whatsapp-db`
3. Easypanel lo configura autom√°ticamente
4. Anota la URL de conexi√≥n

---

## ü§ñ Paso 5: Agregar tu Bot

### 5.1 Crear Servicio
1. Click **"Add Service"** ‚Üí **"App"**
2. Nombre: `whatsapp-bot`

### 5.2 Configurar GitHub
- **Source:** GitHub
- **Propietario:** `daveymena`
- **Repositorio:** `bot-intelogente`
- **Rama:** `main`
- **Ruta de compilaci√≥n:** `.`
- **Build Method:** Dockerfile

### 5.3 Variables de Entorno

```env
# Base de Datos
DATABASE_PROVIDER=postgresql
DATABASE_URL=postgresql://postgres:password@whatsapp-db:5432/postgres

# Autenticaci√≥n
NODE_ENV=production
NEXTAUTH_SECRET=genera-uno-seguro-con-openssl
NEXTAUTH_URL=http://tu-dominio-o-ip

# Ollama (IA Local)
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TIMEOUT=30000

# Configuraci√≥n de IA
AI_PROVIDER=ollama
DEFAULT_AI_PROVIDER=ollama
AI_FALLBACK_ENABLED=true
AI_FALLBACK_ORDER=ollama,openrouter,groq

# Respaldo (Opcional - si Ollama falla)
GROQ_API_KEY=tu_groq_key_opcional
OPENROUTER_API_KEY=tu_openrouter_key_opcional

# WhatsApp
WHATSAPP_PROVIDER=baileys
SESSION_PATH=/app/whatsapp-sessions
PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
PUPPETEER_EXECUTABLE_PATH=/usr/bin/google-chrome-stable
PUPPETEER_HEADLESS=true
PUPPETEER_SANDBOX=false

# Admin
ADMIN_EMAIL=tu@email.com
ADMIN_PASSWORD=tu-password-seguro
CREATE_ADMIN=true
RUN_MIGRATIONS=true

# Puerto
PORT=3000
```

### 5.4 Agregar Volumen para WhatsApp
1. En **"Mounts"**
2. Click **"Add Mount"**
3. **Path:** `/app/whatsapp-sessions`
4. **Size:** 1 GB

### 5.5 Deploy
Click en **"Deploy"**

---

## ‚úÖ Paso 6: Verificar que Funciona

### 6.1 Verificar Ollama
1. Ve al servicio **"ollama"**
2. Click en **"Logs"**
3. Deber√≠as ver: `Ollama is running`

### 6.2 Verificar Bot
1. Ve al servicio **"whatsapp-bot"**
2. Click en **"Logs"**
3. Busca: `[AI Multi-Provider] ‚úÖ √âxito con: ollama`

### 6.3 Probar el Bot
1. Abre la URL de tu bot
2. Inicia sesi√≥n
3. Conecta WhatsApp
4. Env√≠a un mensaje de prueba
5. El bot deber√≠a responder usando Ollama

---

## üéØ Modelos Recomendados por Uso

### Para tu VPS (8GB RAM):

| Modelo | RAM | Velocidad | Calidad | Uso |
|--------|-----|-----------|---------|-----|
| `llama3.2` | 2GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Respuestas r√°pidas |
| `llama3.1` | 5GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Conversaciones complejas |
| `mistral` | 4GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Excelente espa√±ol |
| `phi3` | 2GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Muy r√°pido |

### Comandos para cambiar modelo:

```bash
# En el terminal de Ollama
ollama pull llama3.1
```

Luego actualiza la variable en Easypanel:
```env
OLLAMA_MODEL=llama3.1
```

---

## üí∞ Comparaci√≥n de Costos

| Proveedor | Costo/mes | L√≠mites |
|-----------|-----------|---------|
| **Ollama** | $0 | Ilimitado |
| OpenRouter | $10-50 | Por tokens |
| Groq | Gratis | 30 req/min |
| OpenAI | $20-100 | Por tokens |

---

## üîß Troubleshooting

### Ollama no responde
```bash
# En terminal de Ollama
ollama list  # Ver modelos instalados
ollama ps    # Ver modelos en ejecuci√≥n
```

### Bot no conecta con Ollama
Verifica que la URL sea correcta:
```env
OLLAMA_URL=http://ollama:11434
```

En Easypanel, los servicios se comunican por nombre.

### Modelo muy lento
Cambia a un modelo m√°s ligero:
```bash
ollama pull llama3.2  # M√°s r√°pido
```

### Se queda sin RAM
Usa un modelo m√°s peque√±o o aumenta RAM del VPS.

---

## üéâ ¬°Listo!

Tu bot ahora usa Ollama:
- ‚úÖ Sin costos de API
- ‚úÖ Respuestas ilimitadas
- ‚úÖ Privacidad total
- ‚úÖ Fallback a OpenRouter/Groq si falla

---

## üìä Uso de Recursos

Con Ollama + Bot + PostgreSQL:

| Servicio | CPU | RAM | Disco |
|----------|-----|-----|-------|
| Ollama | 20% | 2-5GB | 10GB |
| Bot | 10% | 300MB | 2GB |
| PostgreSQL | 5% | 100MB | 1GB |
| **Total** | 35% | 2.4-5.4GB | 13GB |

**Tu VPS:** 4 vCPU, 8GB RAM, 75GB
**Sobra:** 65% CPU, 2.6-5.6GB RAM, 62GB disco

¬°Perfecto! üéØ

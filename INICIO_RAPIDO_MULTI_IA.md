# ğŸš€ Inicio RÃ¡pido: Sistema Multi-Provider de IA

## âš¡ En 3 Pasos

### 1ï¸âƒ£ Instalar LM Studio (5 minutos)

1. Descarga: https://lmstudio.ai/
2. Instala y abre
3. Descarga el modelo `phi-2`
4. Settings â†’ Activa **"Enable local REST API server"**

### 2ï¸âƒ£ Activar el Sistema

En tu archivo `.env`, verifica que estÃ©:

```env
AI_FALLBACK_ENABLED=true
AI_FALLBACK_ORDER=groq,lmstudio,openai
```

### 3ï¸âƒ£ Probar

```bash
# Ejecuta el test
probar-multi-provider.bat

# O manualmente
npx tsx scripts/test-multi-provider.ts
```

## âœ… VerificaciÃ³n RÃ¡pida

DeberÃ­as ver:

```
âœ… GROQ: FUNCIONANDO
âœ… LMSTUDIO: FUNCIONANDO
```

## ğŸ¯ Â¿QuÃ© Hace?

Si Groq falla â†’ usa LM Studio automÃ¡ticamente
Si LM Studio falla â†’ usa OpenAI (si estÃ¡ configurado)

**Tu bot NUNCA se quedarÃ¡ sin respuestas** ğŸ‰

## ğŸ”§ ConfiguraciÃ³n MÃ­nima

Solo necesitas:

1. **LM Studio ejecutÃ¡ndose** (local, gratis, sin lÃ­mites)
2. **GROQ_API_KEY** en `.env` (ya lo tienes)
3. **Activar el sistema** con `AI_FALLBACK_ENABLED=true`

## ğŸ“ Problema ComÃºn

**Error: LM Studio no funciona**

SoluciÃ³n:
1. Abre LM Studio
2. Carga el modelo phi-2
3. Settings â†’ Enable local REST API server
4. Verifica que estÃ© en puerto 1234

## ğŸ® Usar en el Bot

Ya estÃ¡ integrado automÃ¡ticamente. Solo:

```bash
npm run dev
```

El bot usarÃ¡ el sistema multi-provider sin configuraciÃ³n adicional.

## ğŸ“Š Ver QuÃ© Provider Usa

En los logs verÃ¡s:

```
[AI] âœ… Respuesta generada con: groq (llama-3.1-8b-instant)
```

O si Groq falla:

```
[AI] âœ… Respuesta generada con: lmstudio (phi-2)
```

---

**Â¡Listo! Tu bot ahora tiene respaldo automÃ¡tico de IA** ğŸš€

Lee `GUIA_MULTI_PROVIDER_IA.md` para mÃ¡s detalles.

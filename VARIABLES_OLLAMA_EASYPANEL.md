# ü§ñ Variables de Ollama para Easypanel

## Variables Necesarias

Agrega estas 3 variables en la configuraci√≥n de tu proyecto en Easypanel:

### 1. OLLAMA_BASE_URL
```
OLLAMA_BASE_URL=https://bot-whatsapp-ollama.sqaoeo.easypanel.host
```
**Descripci√≥n**: URL de tu servidor Ollama en Easypanel

**Nota**: Si tienes Ollama en otro servidor, usa esa URL. Si no tienes Ollama instalado, puedes:
- Dejarlo vac√≠o (el sistema usar√° Groq/OpenRouter)
- O instalar Ollama en Easypanel (ver gu√≠a abajo)

### 2. OLLAMA_MODEL
```
OLLAMA_MODEL=gemma:2b
```
**Descripci√≥n**: Modelo de IA a usar

**Opciones recomendadas**:
- `gemma:2b` - R√°pido y ligero (2GB RAM)
- `llama3.2:3b` - M√°s inteligente (3GB RAM)
- `mistral:7b` - Muy bueno (7GB RAM)
- `llama3.1:8b` - Excelente (8GB RAM)

### 3. OLLAMA_ENABLED
```
OLLAMA_ENABLED=true
```
**Descripci√≥n**: Activar/desactivar Ollama

**Valores**:
- `true` - Usar Ollama como IA principal
- `false` - Desactivar Ollama (usar Groq/OpenRouter)

## üìã C√≥mo Agregar en Easypanel

### Opci√≥n 1: Desde la Interfaz Web

1. Ve a tu proyecto en Easypanel
2. Clic en **"Settings"** o **"Environment"**
3. Busca la secci√≥n **"Environment Variables"**
4. Agrega cada variable:
   ```
   Name: OLLAMA_BASE_URL
   Value: https://bot-whatsapp-ollama.sqaoeo.easypanel.host
   ```
5. Repite para `OLLAMA_MODEL` y `OLLAMA_ENABLED`
6. Clic en **"Save"** o **"Update"**
7. **Redeploy** la aplicaci√≥n

### Opci√≥n 2: Desde Build Args (Dockerfile)

Si usas build args, agr√©galos as√≠:
```dockerfile
--build-arg 'OLLAMA_BASE_URL=https://bot-whatsapp-ollama.sqaoeo.easypanel.host'
--build-arg 'OLLAMA_MODEL=gemma:2b'
--build-arg 'OLLAMA_ENABLED=true'
```

## üéØ Configuraci√≥n Recomendada para Producci√≥n

### Si TIENES Ollama instalado:
```env
OLLAMA_BASE_URL=https://tu-ollama.easypanel.host
OLLAMA_MODEL=gemma:2b
OLLAMA_ENABLED=true
AI_PROVIDER=ollama
AI_FALLBACK_ORDER=ollama,groq,openrouter
```

### Si NO TIENES Ollama (solo APIs):
```env
OLLAMA_ENABLED=false
AI_PROVIDER=groq
AI_FALLBACK_ORDER=groq,openrouter
```

## üöÄ Instalar Ollama en Easypanel (Opcional)

Si quieres usar Ollama (IA local gratis):

1. **Crear nuevo servicio en Easypanel**:
   - Name: `ollama`
   - Image: `ollama/ollama:latest`
   - Port: `11434`

2. **Configurar volumen**:
   - Mount path: `/root/.ollama`
   - Para persistir los modelos

3. **Exponer servicio**:
   - Enable public access
   - Obt√©n la URL (ej: `https://ollama.sqaoeo.easypanel.host`)

4. **Descargar modelo**:
   ```bash
   # Conectar al contenedor
   docker exec -it ollama ollama pull gemma:2b
   ```

5. **Usar la URL en tu bot**:
   ```env
   OLLAMA_BASE_URL=https://ollama.sqaoeo.easypanel.host
   ```

## ‚úÖ Verificar que Funciona

Una vez configurado, el sistema:
1. Intentar√° usar Ollama primero (si est√° habilitado)
2. Si falla, usar√° Groq autom√°ticamente
3. Si Groq falla, usar√° OpenRouter
4. Todo es transparente para el usuario

## üîß Troubleshooting

### Error: "Cannot connect to Ollama"
- Verifica que `OLLAMA_BASE_URL` sea correcta
- Verifica que el servicio Ollama est√© corriendo
- Prueba la URL en el navegador: `https://tu-ollama/api/tags`

### Error: "Model not found"
- El modelo no est√° descargado en Ollama
- Con√©ctate al contenedor y desc√°rgalo:
  ```bash
  ollama pull gemma:2b
  ```

### Ollama muy lento
- Usa un modelo m√°s peque√±o: `gemma:2b`
- Aumenta recursos del servidor
- O desactiva Ollama y usa solo Groq

## üí° Recomendaci√≥n

Para empezar r√°pido en producci√≥n:
```env
# Desactiva Ollama por ahora
OLLAMA_ENABLED=false

# Usa Groq como principal (es gratis y r√°pido)
AI_PROVIDER=groq
AI_FALLBACK_ORDER=groq,openrouter
```

Luego, cuando tengas tiempo, instala Ollama para tener IA local gratis.

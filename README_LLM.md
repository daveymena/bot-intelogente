# ü§ñ Sistema LLM del Bot WhatsApp

## üöÄ Inicio R√°pido

### 1. Iniciar el Bot
```bash
npm run dev
```

### 2. Probar el LLM
```bash
npm run test:llm
# o
test-llm.bat
```

### 3. Mejorar el LLM
```bash
npm run analyze:llm
# o
mejorar-llm.bat
```

---

## üìö Documentaci√≥n

### Archivos Principales

| Archivo | Descripci√≥n |
|---------|-------------|
| `ESTADO_LLM_BOT_ACTUAL.md` | Estado completo del sistema |
| `GUIA_COMPLETA_LLM.md` | Gu√≠a detallada de uso |
| `RESUMEN_SISTEMA_LLM_COMPLETO.md` | Resumen ejecutivo |
| `llm-config.json` | Configuraci√≥n del LLM |

---

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno (.env)

```env
# IA Principal
AI_PROVIDER=groq
GROQ_API_KEY=tu_api_key_aqui
GROQ_MODEL=llama-3.1-8b-instant
GROQ_MAX_TOKENS=300

# Caracter√≠sticas
AI_ENABLED=true
PHOTOS_ENABLED=true
AUDIO_ENABLED=true
```

### Configuraci√≥n del LLM (llm-config.json)

```json
{
  "groq": {
    "model": "llama-3.1-8b-instant",
    "maxTokens": 300,
    "temperature": 0.7
  }
}
```

---

## üéØ Caracter√≠sticas

‚úÖ **Respuestas Inteligentes**
- Modelo: Llama 3.1 (8B instant)
- Velocidad: 1-2 segundos
- Precisi√≥n: 85-95%

‚úÖ **Sistema de Prioridades**
- Respuestas directas (< 100ms)
- Detecci√≥n autom√°tica
- IA conversacional

‚úÖ **Contexto de Conversaci√≥n**
- Memoria de 24 horas
- √öltimos 10 mensajes
- Contexto de productos

‚úÖ **Automatizaci√≥n**
- Env√≠o autom√°tico de fotos
- Links de pago din√°micos
- Escalamiento a humano

---

## üß™ Testing

### Test Completo
```bash
npm run test:llm
```

Prueba:
1. Respuestas directas
2. Detecci√≥n de fotos/pagos
3. B√∫squeda de productos
4. Flujo de conversaci√≥n
5. Formato de respuestas
6. Rendimiento

### An√°lisis y Mejora
```bash
npm run analyze:llm
```

Genera:
- `training-dataset.json` - Dataset de conversaciones
- `optimized-system-prompt.txt` - Prompt optimizado

---

## üé® Personalizaci√≥n

### 1. Cambiar el Tono

Edita `src/lib/ai-service.ts`:
```typescript
const systemPrompt = `
Eres un asistente [AMIGABLE/PROFESIONAL/CASUAL]...
`
```

### 2. Agregar Ejemplos

Edita `src/lib/sales-training-data.ts`:
```typescript
export const TRAINING_SCENARIOS = [
  {
    userMessage: "ejemplo",
    botResponse: "respuesta",
    context: "contexto"
  }
]
```

### 3. Configurar Personalidad

Dashboard ‚Üí Configuraci√≥n ‚Üí Personalidad del Bot

---

## üìä M√©tricas

### Rendimiento
- Respuestas directas: < 100ms
- Groq (IA): 1-2 segundos
- Con fotos: 2-4 segundos

### Precisi√≥n
- Detecci√≥n de productos: 85-95%
- Intenci√≥n de compra: 90%
- Escalamiento: 95%

---

## üêõ Troubleshooting

### El bot no responde
```bash
# Verificar configuraci√≥n
cat .env | grep GROQ

# Probar conexi√≥n
npm run test:llm
```

### Respuestas lentas
```env
# Reducir tokens
GROQ_MAX_TOKENS=200
```

### Respuestas incorrectas
1. Agregar m√°s ejemplos
2. Actualizar productos
3. Refinar system prompt

---

## üìù Comandos √ötiles

```bash
# Iniciar
npm run dev

# Test
npm run test:llm
npm run llm:test

# Mejorar
npm run analyze:llm
npm run llm:improve

# Ver logs
npm run dev | grep "\[AI\]"
```

---

## üîó Enlaces

- [Documentaci√≥n Groq](https://console.groq.com/docs)
- [Llama 3.1](https://ai.meta.com/llama/)
- [Gu√≠a de Prompts](https://www.promptingguide.ai/)

---

## üÜò Soporte

1. Consulta `GUIA_COMPLETA_LLM.md`
2. Ejecuta `npm run test:llm`
3. Revisa los logs

---

**Estado**: ‚úÖ Completamente funcional
**Versi√≥n**: 1.0.0
**√öltima actualizaci√≥n**: 2025-01-09

# âœ… Ollama Configurado con gemma2:4b

## ğŸ¯ ConfiguraciÃ³n Aplicada

### Modelo
- **Modelo**: `gemma2:4b` (3.3 GB)
- **Timeout**: 180 segundos (3 minutos)
- **Max Tokens**: 500
- **URL**: `http://localhost:11434`

### Orden de Fallback
1. **Groq** (Primario) - llama-3.1-8b-instant
2. **Ollama** (Fallback) - gemma2:4b local

## ğŸš€ CÃ³mo Usar

### 1. Verificar que Ollama estÃ© corriendo
```bash
# Ver si Ollama estÃ¡ activo
ollama list

# Si no estÃ¡ corriendo, iniciarlo
ollama serve
```

### 2. Probar Ollama
```bash
# Test rÃ¡pido
node test-ollama-gemma2.js
```

### 3. Entrenar el bot
```bash
# Entrenar con productos reales usando Ollama como fallback
npx tsx scripts/entrenar-bot.ts
```

## ğŸ“Š Ventajas de gemma2:4b

âœ… **Modelo mÃ¡s grande** (4B parÃ¡metros vs 2B)
âœ… **Mejor comprensiÃ³n** del contexto
âœ… **Respuestas mÃ¡s precisas**
âœ… **Sin lÃ­mites de API** (100% local)
âœ… **Sin costos** de tokens

## âš™ï¸ ConfiguraciÃ³n en .env

```env
# Ollama Local
OLLAMA_ENABLED=true
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma2:4b
OLLAMA_TIMEOUT=180000
OLLAMA_MAX_TOKENS=500

# Orden de fallback
AI_FALLBACK_ORDER=groq,ollama
```

## ğŸ”§ Optimizaciones Aplicadas

### En `ollama-service.ts`:
- Timeout aumentado a 3 minutos
- Modelo cambiado a `gemma2:4b`
- ConfiguraciÃ³n optimizada para velocidad

### En `ai-multi-provider.ts`:
- Ollama como segundo en el fallback
- Timeout de 60 segundos para respuestas
- Reintentos automÃ¡ticos

## ğŸ“ˆ Resultados Esperados

Con esta configuraciÃ³n:
- **Groq** maneja el 80% de las consultas (rÃ¡pido)
- **Ollama** toma el control cuando Groq alcanza el lÃ­mite
- **Sin interrupciones** en el servicio
- **Entrenamiento ilimitado** con Ollama

## ğŸ§ª PrÃ³ximos Pasos

1. âœ… ConfiguraciÃ³n aplicada
2. ğŸ”„ Probar con: `node test-ollama-gemma2.js`
3. ğŸ“ Entrenar bot: `npx tsx scripts/entrenar-bot.ts`
4. ğŸ“Š Ver resultados mejorados

## ğŸ’¡ Notas

- gemma2:4b es mÃ¡s lento que gemma:2b pero mÃ¡s preciso
- El timeout de 3 minutos es suficiente para respuestas complejas
- Si es muy lento, puedes volver a gemma:2b cambiando `OLLAMA_MODEL=gemma:2b`

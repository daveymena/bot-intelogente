# ğŸ¦™ GuÃ­a de InstalaciÃ³n de Ollama

Ollama es tu respaldo local ilimitado. Funciona en tu computadora sin necesidad de internet.

## ğŸš€ InstalaciÃ³n RÃ¡pida

### Windows

1. **Descargar Ollama:**
   - Ve a: https://ollama.com/download
   - Descarga el instalador para Windows
   - Ejecuta el instalador

2. **Verificar instalaciÃ³n:**
```bash
ollama --version
```

3. **Descargar un modelo ligero:**
```bash
# Modelo recomendado: Gemma 2B (solo 2GB)
ollama pull gemma:2b

# Alternativas:
ollama pull llama3.2:3b    # 3GB - Mejor calidad
ollama pull phi3:mini      # 2GB - Muy eficiente
```

## ğŸ“‹ Modelos Recomendados

### Para Computadoras con 8GB RAM o menos:
```bash
ollama pull gemma:2b       # MÃ¡s ligero (2GB)
ollama pull phi3:mini      # Muy eficiente (2GB)
```

### Para Computadoras con 16GB RAM o mÃ¡s:
```bash
ollama pull llama3.2:3b    # Balance perfecto (3GB)
ollama pull mistral:7b     # Muy bueno (4GB)
```

## âš™ï¸ ConfiguraciÃ³n en el Bot

Una vez instalado Ollama, agrega esto a tu `.env`:

```env
# Ollama (IA Local - Sin lÃ­mites)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma:2b
OLLAMA_ENABLED=true
OLLAMA_TIMEOUT=60000
```

## ğŸ§ª Probar Ollama

### Desde la terminal:
```bash
# Probar el modelo
ollama run gemma:2b "Hola, Â¿cÃ³mo estÃ¡s?"
```

### Desde el bot:
```bash
node test-triple-respaldo.js
```

## ğŸ’¡ Ventajas de Ollama

- âœ… **Sin lÃ­mites** - Usa cuanto quieras
- âœ… **100% privado** - Todo en tu computadora
- âœ… **Funciona offline** - No necesita internet
- âœ… **Gratis** - Sin costos mensuales
- âœ… **RÃ¡pido** - Respuestas en 3-5 segundos

## ğŸ”§ Comandos Ãštiles

```bash
# Ver modelos instalados
ollama list

# Descargar un modelo
ollama pull gemma:2b

# Eliminar un modelo
ollama rm gemma:2b

# Ver uso de recursos
ollama ps

# Detener Ollama
ollama stop
```

## ğŸ¯ IntegraciÃ³n con el Bot

Una vez instalado, el bot usarÃ¡ Ollama automÃ¡ticamente cuando:
1. Groq alcance su rate limit
2. OpenRouter agote sus 50 mensajes/dÃ­a
3. Cualquier otro provider falle

**No necesitas hacer nada mÃ¡s!** El sistema lo detecta y usa automÃ¡ticamente.

## ğŸ“Š Rendimiento Esperado

| Modelo | RAM Necesaria | Velocidad | Calidad |
|--------|---------------|-----------|---------|
| gemma:2b | 2GB | âš¡âš¡âš¡ RÃ¡pido | â­â­â­ Buena |
| phi3:mini | 2GB | âš¡âš¡âš¡ RÃ¡pido | â­â­â­ Buena |
| llama3.2:3b | 4GB | âš¡âš¡ Medio | â­â­â­â­ Muy buena |
| mistral:7b | 4GB | âš¡âš¡ Medio | â­â­â­â­â­ Excelente |

## ğŸ†˜ SoluciÃ³n de Problemas

### Ollama no inicia:
```bash
# Reiniciar el servicio
ollama serve
```

### Puerto ocupado:
```bash
# Cambiar puerto en .env
OLLAMA_BASE_URL=http://localhost:11435
```

### Modelo muy lento:
```bash
# Usar un modelo mÃ¡s ligero
ollama pull gemma:2b
```

## ğŸ‰ Resultado Final

Con Ollama instalado, tu bot tiene:
- âœ… Groq (principal, rÃ¡pido)
- âœ… OpenRouter (50 msg/dÃ­a gratis)
- âœ… Ollama (ilimitado, local)

**= Sistema 100% resiliente y sin lÃ­mites!** ğŸš€

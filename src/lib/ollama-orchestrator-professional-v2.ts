/**
 * ğŸ¯ OLLAMA ORCHESTRATOR PROFESSIONAL V2
 * Sistema simple y directo - SIN mensajes de "buscando"
 */

import { db } from './db'
import { PaymentAgent } from '../agents/payment-agent'
import { SharedMemoryService } from '../agents/shared-memory'

interface Message {
  role: 'system' | 'user' | 'assistant'
  content: string
}

interface OrchestratorResponse {
  message: string
  source: 'ollama' | 'groq' | 'local' | 'payment_agent'
  confidence: number
  products?: any[]
}

export class OllamaProfessionalOrchestrator {
  private static config = {
    url: process.env.OLLAMA_BASE_URL || process.env.OLLAMA_URL || 'https://davey-ollama2.mapf5v.easypanel.host',
    model: process.env.OLLAMA_MODEL || 'gemma2:2b',
    timeout: parseInt(process.env.OLLAMA_TIMEOUT || '60000') // âœ… Aumentado a 60s
  }

  // CachÃ© de respuestas rÃ¡pidas (solo para casos MUY simples)
  private static quickResponses: Record<string, string> = {
    'gracias': 'Â¡Con gusto! ğŸ˜Š Estoy aquÃ­ para ayudarte. Â¿Necesitas algo mÃ¡s?',
    'ok': 'Â¡Perfecto! ğŸ˜Š Â¿Hay algo mÃ¡s en lo que pueda ayudarte?',
    'vale': 'Â¡Entendido! ğŸ˜Š Cualquier duda, aquÃ­ estoy.',
    'sÃ­': 'Â¡Excelente! ğŸ˜Š',
    'si': 'Â¡Excelente! ğŸ˜Š',
    'no': 'Entendido. Si cambias de opiniÃ³n o necesitas algo, avÃ­same. ğŸ˜Š'
  }

  /**
   * Procesar mensaje
   */
  static async processMessage(
    userMessage: string,
    userId: string,
    conversationHistory: Message[] = [],
    chatId?: string // Opcional por compatibilidad, pero necesario para pagos
  ): Promise<OrchestratorResponse> {
    // Verificar cachÃ©
    const lowerMsg = userMessage.toLowerCase().trim()
    if (this.quickResponses[lowerMsg]) {
      console.log('[Orchestrator] âš¡ Respuesta desde cachÃ©')
      return {
        message: this.quickResponses[lowerMsg],
        source: 'ollama',
        confidence: 100
      }
    }

    // ğŸ¯ DETECCIÃ“N DE INTENCIÃ“N DE PAGO
    if (chatId && this.detectPaymentIntent(userMessage)) {
      console.log('[Orchestrator] ğŸ’³ IntenciÃ³n de pago detectada - Delegando a PaymentAgent')
      try {
        const memoryService = SharedMemoryService.getInstance()
        const memory = memoryService.get(chatId, userId)
        const paymentAgent = new PaymentAgent()
        
        const response = await paymentAgent.execute(userMessage, memory)
        
        return {
          message: response.text,
          source: 'payment_agent',
          confidence: response.confidence || 100
        }
      } catch (error) {
        console.error('[Orchestrator] âŒ Error en PaymentAgent:', error)
        // Fallback a flujo normal
      }
    }

    // Buscar productos
    const products = await this.searchProducts(userMessage, userId)
    console.log(`[Orchestrator] ğŸ” Productos encontrados: ${products.length}`)

    // ğŸ§  DECISIÃ“N INTELIGENTE: Â¿Necesitamos razonamiento de IA?
    const needsAI = this.needsAIReasoning(userMessage, conversationHistory, products)
    
    if (!needsAI && products.length > 0) {
      // âš¡ Respuesta rÃ¡pida para casos simples
      console.log('[Orchestrator] âš¡ Caso simple - Respuesta directa')
      return this.localResponse(userMessage, products)
    }

    // ğŸ¤– Usar Ollama para razonamiento inteligente
    console.log('[Orchestrator] ğŸ§  Usando Ollama para razonamiento inteligente')
    
    // Construir prompt con contexto
    const systemPrompt = this.buildIntelligentPrompt(products, conversationHistory)
    const messages = [
      { role: 'system' as const, content: systemPrompt },
      ...conversationHistory.slice(-6), // Ãšltimos 6 mensajes para contexto
      { role: 'user' as const, content: userMessage }
    ]

    // Llamar Ollama con timeout generoso
    try {
      const response = await this.callOllama(messages)
      return {
        message: response,
        source: 'ollama',
        confidence: 90,
        products: products.length > 0 ? products : undefined
      }
    } catch (error) {
      console.log('[Orchestrator] âŒ Ollama fallÃ³, usando bot local')
      return this.localResponse(userMessage, products)
    }
  }

  /**
   * Detecta si el mensaje es una intenciÃ³n de pago
   */
  private static detectPaymentIntent(message: string): boolean {
    const lower = message.toLowerCase().trim();
    const paymentPatterns = [
      // IntenciÃ³n directa
      /\b(quiero|deseo|me interesa)\s+(pagar|comprar|adquirir)/i,
      /\b(c[oÃ³]mo)\s+(pago|compro|puedo pagar)/i,
      /\b(link|enlace)\s+(de\s+)?(pago|compra)/i,
      /\b(m[eÃ©]todos?|formas?|opci[oÃ³]nes?|medios?)\s+(de\s+)?pago/i,
      
      // MÃ©todos especÃ­ficos
      /\b(mercadopago|mercado pago|paypal|nequi|daviplata|transferencia|consignaci[oÃ³]n)/i,
      /\b(tarjeta|cr[eÃ©]dito|d[eÃ©]bito|pse|efectivo|bancolombia)/i,
      
      // Proceder con compra
      /\b(proceder|continuar|seguir)\s+(con\s+)?(el\s+|la\s+)?(pago|compra)/i,
      /\b(me\s+lo\s+llevo|lo\s+compro|lo\s+quiero|estoy\s+listo)/i,
      
      // SelecciÃ³n numÃ©rica o corta
      /^(1|2|3|4|5|mercadopago|paypal|nequi|daviplata)$/i,
    ];
    return paymentPatterns.some(p => p.test(lower));
  }

  /**
   * Buscar productos usando el sistema inteligente
   */
  private static async searchProducts(query: string, userId: string): Promise<any[]> {
    try {
      const { intelligentProductSearch } = await import('./intelligent-product-search')
      
      const result = await intelligentProductSearch({
        userMessage: query,
        previousProducts: [],
        conversationHistory: []
      })

      if (!result) return []

      if (result.isGeneralQuery && result.products) {
        return result.products.slice(0, 3)
      }

      if (result.product) {
        return [result.product]
      }

      return []
    } catch (error) {
      console.error('[Orchestrator] Error en bÃºsqueda inteligente:', error)
      return []
    }
  }

  /**
   * Detecta si necesitamos razonamiento de IA
   */
  private static needsAIReasoning(
    message: string,
    history: Message[],
    products: any[]
  ): boolean {
    const lowerMsg = message.toLowerCase()

    // âœ… Siempre usar IA para:
    
    // 1. Saludos iniciales (primera impresiÃ³n)
    if (history.length === 0 && (
      lowerMsg.includes('hola') || 
      lowerMsg.includes('buenos') ||
      lowerMsg.includes('buenas')
    )) {
      return true
    }

    // 2. Preguntas complejas
    if (
      lowerMsg.includes('diferencia') ||
      lowerMsg.includes('comparar') ||
      lowerMsg.includes('mejor') ||
      lowerMsg.includes('recomienda') ||
      lowerMsg.includes('cuÃ¡l') ||
      lowerMsg.includes('por quÃ©') ||
      lowerMsg.includes('cÃ³mo')
    ) {
      return true
    }

    // 3. Preguntas sobre caracterÃ­sticas
    if (
      lowerMsg.includes('caracterÃ­sticas') ||
      lowerMsg.includes('especificaciones') ||
      lowerMsg.includes('incluye') ||
      lowerMsg.includes('viene con')
    ) {
      return true
    }

    // 4. Dudas o consultas
    if (
      lowerMsg.includes('duda') ||
      lowerMsg.includes('pregunta') ||
      lowerMsg.includes('consulta') ||
      lowerMsg.includes('saber')
    ) {
      return true
    }

    // 5. ConversaciÃ³n con contexto (mÃ¡s de 3 mensajes)
    if (history.length > 3) {
      return true
    }

    // âš¡ Casos simples (respuesta directa):
    // - "Me interesa X" con producto encontrado
    // - "CuÃ¡nto cuesta" con producto en contexto
    // - "Ok", "Gracias", etc.
    
    return false
  }

  /**
   * Construir prompt inteligente con memoria
   */
  private static buildIntelligentPrompt(
    products: any[],
    history: Message[]
  ): string {
    let prompt = `Eres Alex, asesor de ventas de Tecnovariedades D&S.

ğŸ¯ TU PERSONALIDAD:
- Profesional pero cercana
- Experta en tecnologÃ­a y productos digitales
- Ayudas a los clientes a tomar la mejor decisiÃ³n
- Respondes con empatÃ­a y claridad

ğŸ“‹ INFORMACIÃ“N DE LA EMPRESA:
- Nombre: Tecnovariedades D&S
- UbicaciÃ³n: Centro Comercial El Diamante 2, San NicolÃ¡s, Cali
- WhatsApp: +57 304 274 8687
- Email: deinermen25@gmail.com
- Especialidad: TecnologÃ­a (laptops, accesorios) y Cursos Digitales

ğŸ’¡ TU TRABAJO:
1. Entender quÃ© necesita el cliente (uso, presupuesto, preferencias)
2. Recomendar el producto mÃ¡s adecuado
3. Explicar beneficios (no solo caracterÃ­sticas)
4. Resolver dudas con claridad
5. Guiar hacia la compra de forma natural

ğŸ¨ ESTILO DE COMUNICACIÃ“N:
- Natural y conversacional (no robÃ³tico)
- Emojis sutiles (1-2 por mensaje)
- Respuestas concisas pero completas
- Preguntas inteligentes para entender mejor

ğŸš« NUNCA:
- Digas "Un momento", "buscando", "dÃ©jame buscar"
- Repitas el saludo si ya saludaste
- Uses "OpciÃ³n 1", "OpciÃ³n 2" (habla natural)
- Inventes informaciÃ³n que no tienes

`

    // Agregar contexto de productos
    if (products.length === 1) {
      const p = products[0]
      prompt += `\nğŸ“¦ PRODUCTO DISPONIBLE:\n`
      prompt += `- Nombre: ${p.name}\n`
      prompt += `- Precio: ${p.price.toLocaleString('es-CO')} COP\n`
      if (p.description) {
        prompt += `- DescripciÃ³n: ${p.description.substring(0, 200)}...\n`
      }
      prompt += `\nğŸ’¬ Presenta este producto de forma natural, destacando sus beneficios.\n`
    } else if (products.length > 1) {
      prompt += `\nğŸ“¦ PRODUCTOS DISPONIBLES (${products.length}):\n`
      products.slice(0, 3).forEach((p, i) => {
        prompt += `${i + 1}. ${p.name} - ${p.price.toLocaleString('es-CO')} COP\n`
      })
      prompt += `\nğŸ’¬ Ayuda al cliente a elegir el mejor segÃºn sus necesidades.\n`
    }

    // Agregar contexto de conversaciÃ³n
    if (history.length > 0) {
      prompt += `\nğŸ“ CONTEXTO DE LA CONVERSACIÃ“N:\n`
      const recentHistory = history.slice(-4)
      recentHistory.forEach(msg => {
        if (msg.role === 'user') {
          prompt += `Cliente: ${msg.content}\n`
        } else if (msg.role === 'assistant') {
          prompt += `TÃº: ${msg.content}\n`
        }
      })
      prompt += `\nğŸ’¡ ContinÃºa la conversaciÃ³n de forma natural, recordando el contexto.\n`
    }

    return prompt
  }

  /**
   * Construir prompt - VERSIÃ“N DIRECTA SIN MENSAJES DE "BUSCANDO"
   */
  private static buildPrompt(products: any[]): string {
    const basePrompt = 'Eres Alex, vendedor de Tecnovariedades D&S por WhatsApp.\n\n' +
      'REGLAS CRÃTICAS:\n' +
      '- NUNCA digas "Un momento", "buscando", "dÃ©jame buscar"\n' +
      '- NUNCA menciones "OpciÃ³n 1", "OpciÃ³n 2", etc.\n' +
      '- NO repitas el saludo\n' +
      '- Responde DIRECTO y NATURAL\n' +
      '- MÃ¡ximo 2 lÃ­neas\n' +
      '- Emojis sutiles\n\n' +
      'AGENTES (YA trabajaron):\n' +
      '- BÃºsqueda: YA encontrÃ³ productos\n' +
      '- Fotos: YA enviÃ³ imÃ¡genes\n' +
      '- TÃš solo hablas natural\n\n'

    if (products.length === 1) {
      const p = products[0]
      return basePrompt +
        `PRODUCTO: ${p.name} - ${p.price.toLocaleString('es-CO')} COP\n` +
        `RESPONDE: "Â¡Perfecto! Te enviÃ© la info del ${p.name}. Â¿Te interesa?"\n`
    } else if (products.length > 1) {
      let productList = 'PRODUCTOS:\n'
      products.forEach((p, i) => {
        productList += `${i + 1}. ${p.name} - ${p.price.toLocaleString('es-CO')} COP\n`
      })
      return basePrompt + productList +
        `RESPONDE: "Â¡Claro que sÃ­! ğŸ¤© AquÃ­ te comparto nuestras mejores opciones disponibles. Te enviarÃ© las fotos para que las veas con detalle.\n\n` +
        `ğŸ’¡ AdemÃ¡s, tenemos MÃS variedad segÃºn el uso que le quieras dar (estudio, trabajo pesado, diseÃ±o, gaming, etc.). CuÃ©ntame y te recomiendo la opciÃ³n perfecta para ti ğŸ˜Š"\n`
    } else {
      // Caso: 0 productos encontrados
      return basePrompt +
        `SITUACIÃ“N: El cliente busca algo pero NO se encontraron productos exactos en la base de datos.\n` +
        `RESPONDE: "Lo siento ğŸ˜”, en este momento no encontrÃ© productos exactos con esa descripciÃ³n. Â¿PodrÃ­as darme mÃ¡s detalles o buscas algo diferente?"\n`
    }

    return basePrompt
  }

  /**
   * Llamar Ollama
   */
  private static async callOllama(messages: Message[]): Promise<string> {
    const prompt = messages.map(m => {
      if (m.role === 'system') return m.content
      if (m.role === 'user') return `Cliente: ${m.content}`
      return `Alex: ${m.content}`
    }).join('\n\n') + '\n\nAlex: '

    console.log(`[Ollama] ğŸŒ Conectando a: ${this.config.url}`)
    console.log(`[Ollama] ğŸ¤– Modelo: ${this.config.model}`)
    console.log(`[Ollama] â±ï¸ Timeout: ${this.config.timeout}ms`)

    const controller = new AbortController()
    const timeoutId = setTimeout(() => {
      console.log(`[Ollama] â° Timeout alcanzado (${this.config.timeout}ms)`)
      controller.abort()
    }, this.config.timeout)

    try {
      const startTime = Date.now()
      const response = await fetch(`${this.config.url}/api/generate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: this.config.model,
          prompt,
          stream: false,
          options: {
            temperature: 0.6,
            num_predict: 150,
            repeat_penalty: 1.2
          }
        }),
        signal: controller.signal
      })

      clearTimeout(timeoutId)
      const elapsed = Date.now() - startTime

      if (!response.ok) {
        console.log(`[Ollama] âŒ HTTP ${response.status}`)
        throw new Error(`Ollama HTTP ${response.status}`)
      }

      const data = await response.json()
      console.log(`[Ollama] âœ… Respuesta recibida (${elapsed}ms)`)
      return data.response || ''
    } catch (error: any) {
      clearTimeout(timeoutId)
      console.log(`[Ollama] âŒ Error: ${error.message}`)
      if (error.name === 'AbortError') {
        console.log(`[Ollama] â° OperaciÃ³n abortada por timeout`)
      }
      throw error
    }
  }

  /**
   * Respuesta local (fallback)
   */
  private static localResponse(message: string, products: any[]): OrchestratorResponse {
    const lowerMsg = message.toLowerCase()

    if (products.length === 1) {
      const p = products[0]
      return {
        message: `Â¡Perfecto! ğŸ˜Š Te enviÃ© la info del ${p.name}. Â¿Te interesa?`,
        source: 'local',
        confidence: 80,
        products
      }
    }

    if (products.length > 1) {
      return {
        message: `Â¡Claro! ğŸ˜Š Te enviÃ© ${products.length} opciones. Â¿CuÃ¡l te gusta mÃ¡s?`,
        source: 'local',
        confidence: 75,
        products
      }
    }

    if (lowerMsg.includes('pago') || lowerMsg.includes('pagar')) {
      return {
        message: 'Puedes pagar con MercadoPago, PayPal, Nequi o Daviplata. Â¿CuÃ¡l prefieres? ğŸ˜Š',
        source: 'local',
        confidence: 90
      }
    }

    return {
      message: 'ğŸ˜Š Â¿En quÃ© puedo ayudarte? Tenemos laptops, cursos y megapacks.',
      source: 'local',
      confidence: 60
    }
  }

  /**
   * Verificar disponibilidad
   */
  static async isAvailable(): Promise<boolean> {
    try {
      const response = await fetch(`${this.config.url}/api/tags`, {
        signal: AbortSignal.timeout(3000)
      })
      return response.ok
    } catch {
      return false
    }
  }
}

/*
 * ü§ñ OpenClaw Agent System v1.0
 * El "director de orquesta" que analiza intenciones y decide qu√© herramientas usar.
 * Implementado para TecnoVariedades D&S
 */

import dotenv from 'dotenv';
dotenv.config();

/**
 * üõ†Ô∏è SISTEMA DE HERRAMIENTAS (TOOLS)
 * Define capacidades adicionales para la IA
 */
export const TOOLS = {
    get_payment_info: {
        name: 'get_payment_info',
        description: 'Obtiene detalles de cuentas bancarias (Bancolombia) y Nequi para concretar la venta.',
        parameters: {},
        execute: async (params, context) => {
            return {
                success: true,
                data: {
                    bank: {
                        name: process.env.BANK_NAME || 'Bancolombia',
                        account: process.env.BANK_ACCOUNT_NUMBER || '1234567890',
                        holder: process.env.BANK_ACCOUNT_HOLDER || 'Nombre Titular'
                    },
                    nequi: {
                        number: process.env.NEQUI_NUMBER || '3136174267'
                    }
                }
            };
        }
    },
    get_product_details: {
        name: 'get_product_details',
        description: 'Obtiene detalles t√©cnicos y links de pago de un producto espec√≠fico.',
        parameters: {
            productId: { type: 'string', description: 'ID √∫nico del producto' }
        },
        execute: async (params, context) => {
            const product = context.products.find(p => p.id === params.productId);
            if (!product) return { success: false, message: 'Producto no encontrado' };
            return { success: true, data: product };
        }
    }
};

class OpenClawAgent {
    constructor() {
        this.conversationHistory = new Map();
        this.maxHistory = 20;
    }

    /**
     * Procesa un mensaje entrante y decide la mejor acci√≥n
     * @param {string} messageText - El texto enviado por el usuario
     * @param {string} from - ID del usuario (n√∫mero de tel√©fono)
     * @param {object} contextBot - Datos del negocio y productos
     */
    async processMessage(messageText, from, contextBot) {
        try {
            console.log(`[OpenClaw] üì© Procesando de ${from}: "${messageText}"`);
            
            // 1. Gestionar Memoria
            if (!this.conversationHistory.has(from)) {
                this.conversationHistory.set(from, []);
            }
            const history = this.conversationHistory.get(from);

            // 2. An√°lisis de Intenci√≥n (Clasificaci√≥n Interna)
            const analysis = await this._analyzeIntention(messageText, history, contextBot);
            
            let toolResult = null;
            if (analysis.toolToUse && TOOLS[analysis.toolToUse]) {
                console.log(`[OpenClaw] üîß Ejecutando herramienta: ${analysis.toolToUse}`);
                toolResult = await TOOLS[analysis.toolToUse].execute(analysis.toolParams, contextBot);
            }

            // 3. Generar Respuesta con el Proveedor configurado
            const response = await this._generateResponse(messageText, history, contextBot, toolResult);

            // 4. Actualizar Memoria (limitar a 20 mensajes)
            history.push({ role: 'user', content: messageText });
            history.push({ role: 'assistant', content: response });
            if (history.length > this.maxHistory * 2) {
                this.conversationHistory.set(from, history.slice(-this.maxHistory * 2));
            }

            return { 
                text: response, 
                toolUsed: analysis.toolToUse,
                success: true
            };
        } catch (error) {
            console.error('[OpenClaw Agent Error]:', error);
            return { 
                text: "David: Tuve un peque√±o contratiempo procesando tu solicitud. ¬°Pero aqu√≠ estoy! ¬øQu√© necesitas exactamente? üòä",
                success: false
            };
        }
    }

    /**
     * Clasificador de intenciones ultra-r√°pido
     */
    async _analyzeIntention(text, history, context) {
        const lowerText = text.toLowerCase();
        
        // Detecci√≥n simple para pagos
        if (lowerText.includes('pagar') || lowerText.includes('nequi') || lowerText.includes('cuenta') || lowerText.includes('bancolombia')) {
            return { toolToUse: 'get_payment_info', toolParams: {} };
        }

        // Detecci√≥n de productos espec√≠ficos
        const productMatch = context.products.find(p => lowerText.includes(p.name.toLowerCase()));
        if (productMatch) {
            return { toolToUse: 'get_product_details', toolParams: { productId: productMatch.id } };
        }

        return { toolToUse: null, toolParams: {} };
    }

    /**
     * Motor de Generaci√≥n de Respuesta (Ollama/Groq)
     */
    async _generateResponse(userMessage, history, context, toolResult) {
        const provider = process.env.AI_PROVIDER || 'ollama';
        
        const systemPrompt = `
Eres David, el asistente virtual oficial de "${context.business.name}".
PERSONALIDAD: Profesional, innovador, extremadamente servicial y persuasivo. Usa emojis (üöÄ, ‚úÖ, üíª, üí≥) para que la charla sea amena.

CONTEXTO DEL NEGOCIO:
${JSON.stringify(context.business)}

${toolResult ? `DATOS OBTENIDOS (HERRAMIENTA): ${JSON.stringify(toolResult.data)}` : ''}

INFORMACI√ìN DE PRODUCTOS DISPONIBLES:
${context.products.map(p => `- ${p.name}: $${p.price} ${p.currency}`).join('\n')}

INSTRUCCIONES:
1. Si el usuario pregunta por pagos, da la informaci√≥n de Nequi/Bancolombia que recibiste.
2. Si pregunta por un producto, resalta sus beneficios (no solo specs).
3. Responde siempre en espa√±ol.
4. Si no sabes algo, invita al usuario a esperar que un humano lo contacte.
        `.trim();

        if (process.env.USE_OLLAMA === 'true' && provider === 'ollama') {
            return await this._callOllama(systemPrompt, history, userMessage);
        } else {
            return await this._callGroq(systemPrompt, history, userMessage);
        }
    }

    async _callGroq(systemPrompt, history, message) {
        const keys = [
            process.env.GROQ_API_KEY,
            process.env.GROQ_API_KEY_2,
            process.env.GROQ_API_KEY_3,
            process.env.GROQ_API_KEY_4,
            process.env.GROQ_API_KEY_5
        ].filter(Boolean);

        for (const key of keys) {
            try {
                const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${key}`,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        model: process.env.GROQ_MODEL || 'llama-3.1-8b-instant',
                        messages: [
                            { role: 'system', content: systemPrompt },
                            ...history,
                            { role: 'user', content: message }
                        ],
                        temperature: 0.7,
                        max_tokens: 800
                    })
                });
                
                if (!response.ok) throw new Error(`Groq HTTP Error: ${response.status}`);
                
                const data = await response.json();
                return data.choices[0].message.content;
            } catch (e) {
                console.error(`[OpenClaw] ‚ö†Ô∏è Error con API Key de Groq, intentando la siguiente...`, e.message);
                continue; // Probar con la siguiente llave
            }
        }
        return "David: Mis sistemas de IA est√°n muy ocupados en este momento. ¬°Pero no te preocupes! D√©jame tu duda y te responder√© en cuanto recupere la conexi√≥n. üòä";
    }

    async _callOllama(systemPrompt, history, message) {
        try {
            const response = await fetch(`${process.env.OLLAMA_BASE_URL || 'http://localhost:11434'}/api/chat`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model: process.env.OLLAMA_MODEL || 'gemma2:2b',
                    messages: [
                        { role: 'system', content: systemPrompt },
                        ...history,
                        { role: 'user', content: message }
                    ],
                    stream: false
                })
            });
            const data = await response.json();
            return data.message.content;
        } catch (e) {
            console.error('Ollama Local Error:', e);
            // Fallback a Groq si Ollama falla
            return await this._callGroq(systemPrompt, history, message);
        }
    }
}

export const openClawAgent = new OpenClawAgent();

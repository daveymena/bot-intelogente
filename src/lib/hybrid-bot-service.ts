/**
 * Hybrid Bot Service
 * Sistema hÃ­brido: Bot Local + Ollama Assistant
 * 
 * FLUJO:
 * 1. Bot local intenta responder con reglas predefinidas
 * 2. Si no sabe, Ollama analiza la intenciÃ³n
 * 3. Ollama mantiene memoria y contexto
 * 4. Ollama genera respuesta inteligente si es necesario
 */

import { OllamaAssistantService } from './ollama-assistant-service';
import { ProductIntelligenceService } from './product-intelligence-service';

interface BotResponse {
  message: string;
  source: 'local' | 'ollama' | 'hybrid';
  confidence: number;
  intent?: string;
  needsHumanEscalation?: boolean;
}

export class HybridBotService {
  /**
   * Respuestas locales predefinidas (rÃ¡pidas y sin costo)
   */
  private static localResponses = {
    saludos: [
      'Â¡Hola! ğŸ‘‹ Bienvenido a Tecnovariedades D&S. Â¿En quÃ© puedo ayudarte hoy?',
      'Â¡Hola! ğŸ˜Š Â¿Buscas algÃºn producto en particular?',
      'Â¡Bienvenido! Estoy aquÃ­ para ayudarte a encontrar lo que necesitas.'
    ],
    despedidas: [
      'Â¡Hasta pronto! ğŸ‘‹ Estamos para servirte cuando lo necesites.',
      'Gracias por contactarnos. Â¡Que tengas un excelente dÃ­a! ğŸ˜Š',
      'Â¡Nos vemos! No dudes en escribirnos cuando quieras.'
    ],
    agradecimientos: [
      'Â¡Con gusto! ğŸ˜Š Â¿Hay algo mÃ¡s en lo que pueda ayudarte?',
      'Para eso estamos. Â¿Necesitas algo mÃ¡s?',
      'Â¡De nada! Estoy aquÃ­ para lo que necesites.'
    ],
    metodosPago: `Aceptamos varios mÃ©todos de pago:
ğŸ’³ Tarjetas de crÃ©dito/dÃ©bito
ğŸ’° Nequi y Daviplata
ğŸ¦ Transferencia bancaria
ğŸ“¦ Contraentrega (segÃºn zona)

Â¿CuÃ¡l prefieres?`,
    infoEnvio: `Hacemos envÃ­os a toda Colombia ğŸ‡¨ğŸ‡´
ğŸ“¦ EnvÃ­o nacional: 2-5 dÃ­as hÃ¡biles
ğŸšš EnvÃ­o express: 1-2 dÃ­as hÃ¡biles
ğŸª Recogida en tienda: Inmediato

Â¿A quÃ© ciudad necesitas el envÃ­o?`
  };

  /**
   * Detectar intenciÃ³n con reglas simples (bot local)
   */
  private static detectLocalIntent(message: string): string | null {
    const msg = message.toLowerCase();

    // Saludos
    if (/^(hola|buenos|buenas|hey|hi|saludos)/i.test(msg)) {
      return 'saludo';
    }

    // Despedidas
    if (/(adios|chao|hasta luego|bye|nos vemos)/i.test(msg)) {
      return 'despedida';
    }

    // Agradecimientos
    if (/(gracias|muchas gracias|te agradezco|thanks)/i.test(msg)) {
      return 'agradecimiento';
    }

    // MÃ©todos de pago
    if (/(como pago|metodos de pago|formas de pago|puedo pagar|aceptan)/i.test(msg)) {
      return 'metodos_pago';
    }

    // EnvÃ­o
    if (/(envio|envios|entregan|delivery|domicilio)/i.test(msg)) {
      return 'info_envio';
    }

    return null;
  }

  /**
   * Respuesta local rÃ¡pida
   */
  private static getLocalResponse(intent: string): string | null {
    switch (intent) {
      case 'saludo':
        return this.localResponses.saludos[Math.floor(Math.random() * this.localResponses.saludos.length)];
      case 'despedida':
        return this.localResponses.despedidas[Math.floor(Math.random() * this.localResponses.despedidas.length)];
      case 'agradecimiento':
        return this.localResponses.agradecimientos[Math.floor(Math.random() * this.localResponses.agradecimientos.length)];
      case 'metodos_pago':
        return this.localResponses.metodosPago;
      case 'info_envio':
        return this.localResponses.infoEnvio;
      default:
        return null;
    }
  }

  /**
   * MÃ‰TODO PRINCIPAL: Procesar mensaje con sistema hÃ­brido
   */
  static async processMessage(
    userMessage: string,
    customerPhone: string,
    userId?: string
  ): Promise<BotResponse> {
    console.log('\nğŸ¤– === SISTEMA HÃBRIDO ===');
    console.log('ğŸ“¨ Mensaje:', userMessage);

    // PASO 1: Intentar respuesta local (rÃ¡pida, sin costo)
    const localIntent = this.detectLocalIntent(userMessage);
    
    if (localIntent) {
      const localResponse = this.getLocalResponse(localIntent);
      if (localResponse) {
        console.log('âœ… Respuesta LOCAL (instantÃ¡nea)');
        
        // Guardar en memoria de Ollama para contexto
        OllamaAssistantService.saveContext(customerPhone, userMessage, 'user');
        OllamaAssistantService.saveContext(customerPhone, localResponse, 'assistant');

        return {
          message: localResponse,
          source: 'local',
          confidence: 0.95,
          intent: localIntent
        };
      }
    }

    // PASO 2: Usar Ollama para anÃ¡lisis de intenciÃ³n (consultas complejas)
    console.log('ğŸ§  Bot local no sabe â†’ Consultando Ollama...');

    try {
      // Obtener contexto previo
      const contextSummary = OllamaAssistantService.getContextSummary(customerPhone);
      const conversationContext = contextSummary.split('\n').filter(l => l.trim());

      // Analizar intenciÃ³n con Ollama
      const intentAnalysis = await OllamaAssistantService.analyzeIntent(
        userMessage,
        conversationContext
      );

      console.log('ğŸ¯ IntenciÃ³n detectada:', intentAnalysis.intent);

      // Guardar contexto
      OllamaAssistantService.saveContext(
        customerPhone,
        userMessage,
        'user',
        {
          intent: intentAnalysis.intent,
          product: intentAnalysis.entities.product,
          budget: intentAnalysis.entities.priceRange ? this.parsePriceRange(intentAnalysis.entities.priceRange) : undefined
        }
      );

      // PASO 3: Buscar productos si es necesario
      let products = [];
      if (intentAnalysis.intent === 'buscar_producto' && intentAnalysis.entities.product) {
        try {
          console.log('ğŸ” Buscando productos...');
          products = await ProductIntelligenceService.searchProducts(
            intentAnalysis.entities.product,
            userId || 'default'
          );
          console.log(`ğŸ“¦ Encontrados: ${products.length} productos`);
        } catch (error) {
          console.log('âš ï¸  Base de datos no disponible, continuando sin productos');
        }
      }

      // PASO 4: Generar respuesta inteligente con Ollama (formateada)
      let intelligentResponse: string;
      
      if (products.length > 0) {
        // Con productos: usar formato especial
        intelligentResponse = await OllamaAssistantService.generateResponseWithProducts(
          userMessage,
          customerPhone,
          products.slice(0, 3)
        );
      } else {
        // Sin productos: respuesta general formateada
        intelligentResponse = await OllamaAssistantService.generateIntelligentResponse(
          userMessage,
          customerPhone,
          []
        );
      }

      // Guardar respuesta en contexto
      OllamaAssistantService.saveContext(customerPhone, intelligentResponse, 'assistant');

      return {
        message: intelligentResponse,
        source: products.length > 0 ? 'hybrid' : 'ollama',
        confidence: intentAnalysis.confidence,
        intent: intentAnalysis.intent,
        needsHumanEscalation: intentAnalysis.needsHumanEscalation
      };

    } catch (error) {
      console.error('âŒ Error en Ollama, usando fallback local');
      
      // Fallback: respuesta genÃ©rica local
      const fallbackResponse = 'Entiendo que necesitas ayuda. Â¿PodrÃ­as darme mÃ¡s detalles sobre lo que buscas? Por ejemplo: laptops, motos, cursos, etc.';
      
      return {
        message: fallbackResponse,
        source: 'local',
        confidence: 0.5,
        intent: 'fallback'
      };
    }
  }

  /**
   * Parsear rango de precio
   */
  private static parsePriceRange(range: string): number {
    const ranges: Record<string, number> = {
      'economico': 500000,
      'bajo': 500000,
      'medio': 1500000,
      'alto': 3000000,
      'premium': 5000000
    };
    return ranges[range.toLowerCase()] || 1000000;
  }

  /**
   * Obtener estadÃ­sticas del sistema
   */
  static async getStats() {
    const ollamaAvailable = await OllamaAssistantService.checkAvailability();
    
    return {
      ollamaAvailable,
      model: process.env.OLLAMA_MODEL || 'llama3:latest',
      baseUrl: process.env.OLLAMA_BASE_URL,
      localResponsesCount: Object.keys(this.localResponses).length
    };
  }
}

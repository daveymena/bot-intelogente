/**
 * üß™ Test de Modelos de Ollama - Velocidad y Disponibilidad
 * Detecta qu√© modelos est√°n disponibles y cu√°l es el m√°s r√°pido
 */

require('dotenv').config()

const OLLAMA_URL = process.env.OLLAMA_BASE_URL || process.env.OLLAMA_URL || 'https://davey-ollama2.mapf5v.easypanel.host'

console.log('üß™ TEST DE MODELOS DE OLLAMA')
console.log('='.repeat(70))
console.log(`üìç URL: ${OLLAMA_URL}`)
console.log('='.repeat(70))
console.log('')

async function testModels() {
  // Paso 1: Obtener modelos disponibles
  console.log('üì¶ Paso 1: Obteniendo modelos disponibles...')
  console.log('')
  
  let models = []
  try {
    const response = await fetch(`${OLLAMA_URL}/api/tags`, {
      signal: AbortSignal.timeout(5000)
    })
    
    if (!response.ok) {
      console.log(`‚ùå Error obteniendo modelos: ${response.status}`)
      return
    }
    
    const data = await response.json()
    models = data.models || []
    
    console.log(`‚úÖ Encontrados ${models.length} modelos:`)
    models.forEach((m, i) => {
      const size = m.size ? `(${(m.size / 1024 / 1024 / 1024).toFixed(1)} GB)` : ''
      console.log(`   ${i + 1}. ${m.name} ${size}`)
    })
  } catch (error) {
    console.log(`‚ùå Error: ${error.message}`)
    return
  }

  if (models.length === 0) {
    console.log('‚ùå No hay modelos disponibles')
    return
  }

  console.log('')
  console.log('='.repeat(70))
  console.log('‚ö° Paso 2: Midiendo velocidad de cada modelo...')
  console.log('='.repeat(70))
  console.log('')

  const testPrompt = 'Responde en una palabra: ¬øC√≥mo est√°s?'
  const results = []

  for (const model of models) {
    console.log(`üß™ Probando: ${model.name}`)
    
    try {
      const startTime = Date.now()
      
      const controller = new AbortController()
      const timeoutId = setTimeout(() => controller.abort(), 30000) // 30s timeout

      const response = await fetch(`${OLLAMA_URL}/api/generate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: model.name,
          prompt: testPrompt,
          stream: false,
          options: {
            temperature: 0.1,
            num_predict: 20
          }
        }),
        signal: controller.signal
      })

      clearTimeout(timeoutId)
      const elapsed = Date.now() - startTime

      if (response.ok) {
        const data = await response.json()
        const responseText = data.response || ''
        
        results.push({
          name: model.name,
          time: elapsed,
          success: true,
          response: responseText.substring(0, 50)
        })
        
        console.log(`   ‚úÖ Tiempo: ${elapsed}ms`)
        console.log(`   üí¨ Respuesta: "${responseText.substring(0, 50)}..."`)
        
        // Clasificar velocidad
        if (elapsed < 2000) {
          console.log(`   ‚ö° MUY R√ÅPIDO`)
        } else if (elapsed < 5000) {
          console.log(`   üü¢ R√ÅPIDO`)
        } else if (elapsed < 10000) {
          console.log(`   üü° NORMAL`)
        } else {
          console.log(`   üî¥ LENTO`)
        }
      } else {
        results.push({
          name: model.name,
          time: elapsed,
          success: false,
          error: `HTTP ${response.status}`
        })
        console.log(`   ‚ùå Error: HTTP ${response.status}`)
      }
    } catch (error) {
      results.push({
        name: model.name,
        time: 30000,
        success: false,
        error: error.message
      })
      console.log(`   ‚ùå Error: ${error.message}`)
    }
    
    console.log('')
  }

  // Resultados finales
  console.log('='.repeat(70))
  console.log('üìä RESULTADOS FINALES')
  console.log('='.repeat(70))
  console.log('')

  // Ordenar por velocidad
  const successful = results.filter(r => r.success).sort((a, b) => a.time - b.time)
  const failed = results.filter(r => !r.success)

  if (successful.length > 0) {
    console.log('‚úÖ MODELOS FUNCIONALES (ordenados por velocidad):')
    console.log('')
    successful.forEach((r, i) => {
      const medal = i === 0 ? 'ü•á' : i === 1 ? 'ü•à' : i === 2 ? 'ü•â' : '  '
      const speed = r.time < 2000 ? '‚ö°' : r.time < 5000 ? 'üü¢' : r.time < 10000 ? 'üü°' : 'üî¥'
      console.log(`${medal} ${speed} ${r.name}`)
      console.log(`      Tiempo: ${r.time}ms`)
      console.log(`      Respuesta: "${r.response}"`)
      console.log('')
    })

    // Recomendaci√≥n
    console.log('='.repeat(70))
    console.log('üí° RECOMENDACI√ìN PARA TU .ENV')
    console.log('='.repeat(70))
    console.log('')
    
    const fastest = successful[0]
    const secondFastest = successful[1]
    
    console.log('Configuraci√≥n √≥ptima:')
    console.log('')
    console.log(`OLLAMA_MODEL=${fastest.name}  # ‚ö° M√°s r√°pido (${fastest.time}ms)`)
    
    if (secondFastest) {
      console.log(`OLLAMA_MODEL_SECONDARY=${secondFastest.name}  # ü•à Fallback (${secondFastest.time}ms)`)
    }
    
    console.log(`OLLAMA_TIMEOUT=${Math.max(fastest.time * 3, 30000)}  # 3x el tiempo promedio`)
    console.log('')
    
    // An√°lisis de velocidad
    if (fastest.time < 2000) {
      console.log('‚úÖ Velocidad excelente - Respuestas casi instant√°neas')
    } else if (fastest.time < 5000) {
      console.log('‚úÖ Velocidad buena - Respuestas r√°pidas')
    } else if (fastest.time < 10000) {
      console.log('‚ö†Ô∏è  Velocidad aceptable - Considera modelo m√°s ligero')
    } else {
      console.log('‚ùå Velocidad lenta - Usa modelo m√°s peque√±o o Groq')
    }
  }

  if (failed.length > 0) {
    console.log('')
    console.log('‚ùå MODELOS CON ERRORES:')
    console.log('')
    failed.forEach(r => {
      console.log(`   ‚Ä¢ ${r.name}: ${r.error}`)
    })
  }

  console.log('')
  console.log('='.repeat(70))
  
  return successful.length > 0
}

// Ejecutar test
testModels().then(success => {
  if (!success) {
    console.log('‚ùå No hay modelos funcionales')
    console.log('')
    console.log('üîß SOLUCIONES:')
    console.log('1. Verifica que Ollama est√© corriendo')
    console.log('2. Verifica la URL en .env')
    console.log('3. Instala modelos: ollama pull gemma2:2b')
    process.exit(1)
  }
  process.exit(0)
}).catch(error => {
  console.error('‚ùå Error fatal:', error)
  process.exit(1)
})

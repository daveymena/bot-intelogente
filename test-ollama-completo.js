/**
 * Test completo del sistema Ollama
 * Verifica:
 * - Conexi√≥n a Ollama
 * - Formato CARD
 * - AIDA
 * - Memoria conversacional
 * - Fotos autom√°ticas
 */

require('dotenv').config();

async function testOllamaCompleto() {
  console.log('üß™ TEST COMPLETO SISTEMA OLLAMA\n');
  console.log('='.repeat(60));

  // 1. Verificar configuraci√≥n
  console.log('\nüìã 1. VERIFICANDO CONFIGURACI√ìN...');
  console.log(`USE_OLLAMA: ${process.env.USE_OLLAMA}`);
  console.log(`OLLAMA_BASE_URL: ${process.env.OLLAMA_BASE_URL}`);
  console.log(`OLLAMA_MODEL: ${process.env.OLLAMA_MODEL}`);
  console.log(`OLLAMA_TIMEOUT: ${process.env.OLLAMA_TIMEOUT}`);

  if (process.env.USE_OLLAMA !== 'true') {
    console.log('‚ùå USE_OLLAMA no est√° activado');
    return;
  }

  // 2. Test de conexi√≥n b√°sica
  console.log('\nüîå 2. TEST DE CONEXI√ìN B√ÅSICA...');
  try {
    const ollamaUrl = process.env.OLLAMA_BASE_URL;
    const response = await fetch(`${ollamaUrl}/api/tags`);
    
    if (response.ok) {
      const data = await response.json();
      console.log('‚úÖ Conexi√≥n exitosa');
      console.log(`üì¶ Modelos disponibles: ${data.models?.length || 0}`);
      data.models?.forEach(m => {
        console.log(`   - ${m.name} (${(m.size / 1024 / 1024 / 1024).toFixed(2)} GB)`);
      });
    } else {
      console.log('‚ùå Error de conexi√≥n:', response.status);
    }
  } catch (error) {
    console.log('‚ùå Error:', error.message);
  }

  // 3. Test de respuesta simple
  console.log('\nüí¨ 3. TEST DE RESPUESTA SIMPLE...');
  try {
    const ollamaUrl = process.env.OLLAMA_BASE_URL;
    const model = process.env.OLLAMA_MODEL;

    const response = await fetch(`${ollamaUrl}/api/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'system',
            content: 'Eres un vendedor profesional. Responde en espa√±ol.'
          },
          {
            role: 'user',
            content: 'Hola, ¬øqu√© productos vendes?'
          }
        ],
        stream: false,
        options: {
          temperature: 0.7,
          num_predict: 300
        }
      })
    });

    if (response.ok) {
      const data = await response.json();
      console.log('‚úÖ Respuesta recibida:');
      console.log(data.message?.content || 'Sin contenido');
    } else {
      console.log('‚ùå Error:', response.status);
    }
  } catch (error) {
    console.log('‚ùå Error:', error.message);
  }

  // 4. Test de formato CARD
  console.log('\nüé¥ 4. TEST DE FORMATO CARD...');
  try {
    const ollamaUrl = process.env.OLLAMA_BASE_URL;
    const model = process.env.OLLAMA_MODEL;

    const producto = {
      nombre: 'Laptop HP 15-fd0033la',
      precio: 1899000,
      categoria: 'FISICO',
      descripcion: 'Intel Core i5, 8GB RAM, 256GB SSD'
    };

    const systemPrompt = `Eres un vendedor profesional de Tecnovariedades D&S.

FORMATO CARD OBLIGATORIO:
üéØ [Emoji] [Nombre del Producto]
üí∞ Precio: $X.XXX COP

üìò Incluye/Caracter√≠sticas:
‚úÖ Caracter√≠stica 1
‚úÖ Caracter√≠stica 2
‚úÖ Caracter√≠stica 3

üß† AIDA:
‚ú® Atenci√≥n: [Gancho inicial]
üî• Inter√©s: [Beneficio principal]
‚≠ê Deseo: [Prueba social]
üëâ Acci√≥n: [Pregunta de cierre]

üí¨ [Pregunta para avanzar]`;

    const userPrompt = `PRODUCTO:
Nombre: ${producto.nombre}
Precio: ${producto.precio.toLocaleString('es-CO')} COP
Categor√≠a: ${producto.categoria}
Descripci√≥n: ${producto.descripcion}

CLIENTE PREGUNTA: "¬øQu√© laptop me recomiendas para trabajar?"

GENERA RESPUESTA CON FORMATO CARD:`;

    const response = await fetch(`${ollamaUrl}/api/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        stream: false,
        options: {
          temperature: 0.7,
          num_predict: 800
        }
      })
    });

    if (response.ok) {
      const data = await response.json();
      console.log('‚úÖ Respuesta CARD generada:');
      console.log('‚îÄ'.repeat(60));
      console.log(data.message?.content || 'Sin contenido');
      console.log('‚îÄ'.repeat(60));
    } else {
      console.log('‚ùå Error:', response.status);
    }
  } catch (error) {
    console.log('‚ùå Error:', error.message);
  }

  // 5. Test de velocidad
  console.log('\n‚ö° 5. TEST DE VELOCIDAD...');
  try {
    const ollamaUrl = process.env.OLLAMA_BASE_URL;
    const model = process.env.OLLAMA_MODEL;

    const inicio = Date.now();

    const response = await fetch(`${ollamaUrl}/api/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'user',
            content: 'Responde en una l√≠nea: ¬øQu√© es una laptop?'
          }
        ],
        stream: false,
        options: {
          temperature: 0.5,
          num_predict: 100
        }
      })
    });

    const tiempo = Date.now() - inicio;

    if (response.ok) {
      const data = await response.json();
      console.log(`‚úÖ Tiempo de respuesta: ${tiempo}ms`);
      console.log(`üìù Respuesta: ${data.message?.content?.substring(0, 100)}...`);
      
      if (tiempo < 5000) {
        console.log('üöÄ Velocidad: EXCELENTE');
      } else if (tiempo < 10000) {
        console.log('‚ö° Velocidad: BUENA');
      } else {
        console.log('üêå Velocidad: LENTA (considerar optimizar)');
      }
    } else {
      console.log('‚ùå Error:', response.status);
    }
  } catch (error) {
    console.log('‚ùå Error:', error.message);
  }

  console.log('\n' + '='.repeat(60));
  console.log('‚úÖ TEST COMPLETO FINALIZADO');
}

// Ejecutar test
testOllamaCompleto().catch(console.error);

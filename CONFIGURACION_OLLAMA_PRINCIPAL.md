# ğŸš€ ConfiguraciÃ³n: Ollama como IA Principal

**Fecha**: 22 de Noviembre 2025  
**PropÃ³sito**: Probar Ollama en Easypanel como proveedor principal de IA

---

## ğŸ¯ ConfiguraciÃ³n

### IA Principal: **Ollama**
- **URL**: `https://ollama-ollama.sqaoeo.easypanel.host`
- **Modelo**: `llama3:8b-instruct-q2_K`
- **TamaÃ±o**: 2.96 GB
- **Velocidad**: 2-8 segundos
- **Costo**: **GRATIS** (sin lÃ­mites)

### Fallback: **Groq**
- Se activa si Ollama falla
- Requiere API keys configuradas
- LÃ­mites: 30 req/min por key

---

## ğŸ“ Activar ConfiguraciÃ³n

### OpciÃ³n 1: Script AutomÃ¡tico
```bash
ACTIVAR_OLLAMA_PRINCIPAL.bat
```

### OpciÃ³n 2: Manual
1. Copiar `.env.ollama-principal` a `.env`
2. Editar `.env` y agregar:
   - `GROQ_API_KEY_1`, `GROQ_API_KEY_2`, `GROQ_API_KEY_3`
   - `DATABASE_URL`
3. Reiniciar servidor: `npm run dev`

---

## âš™ï¸ Variables Clave

```env
# IA Principal
AI_PROVIDER=ollama
OLLAMA_BASE_URL=https://ollama-ollama.sqaoeo.easypanel.host
OLLAMA_MODEL=llama3:8b-instruct-q2_K

# Fallback
AI_FALLBACK_ENABLED=true
GROQ_API_KEY_1=gsk_...
GROQ_API_KEY_2=gsk_...
GROQ_API_KEY_3=gsk_...

# ConfiguraciÃ³n IA
AI_MAX_TOKENS=500
AI_TEMPERATURE=0.7
AI_TIMEOUT=30000
```

---

## ğŸ“Š ComparaciÃ³n: Ollama vs Groq

| CaracterÃ­stica | Ollama | Groq |
|----------------|--------|------|
| **Velocidad** | 2-8s | 1-3s |
| **Costo** | Gratis | Gratis (con lÃ­mites) |
| **LÃ­mites** | Sin lÃ­mites | 30 req/min |
| **Privacidad** | Tu servidor | Externo |
| **Calidad** | Buena | Excelente |
| **Disponibilidad** | 99%+ | 99%+ |

---

## ğŸ¯ Ventajas de Ollama Principal

### âœ… Ventajas:
1. **Sin lÃ­mites de tokens** - Usa todo lo que necesites
2. **Gratis** - No gastas en APIs externas
3. **Privado** - Datos en tu servidor
4. **Predecible** - Sin rate limits
5. **Fallback a Groq** - Si algo falla

### âš ï¸ Consideraciones:
1. **Velocidad** - 2-8s (vs 1-3s de Groq)
2. **Calidad** - Buena pero no excelente
3. **Dependencia** - Requiere servidor Ollama activo

---

## ğŸ§ª Probar ConfiguraciÃ³n

### Test 1: Verificar Ollama
```bash
probar-ollama-easypanel.bat
```

### Test 2: Probar Bot Completo
```bash
npm run dev
```
Luego envÃ­a "Hola" por WhatsApp

### Test 3: Verificar Fallback
1. DetÃ©n el servidor Ollama
2. El sistema debe usar Groq automÃ¡ticamente

---

## ğŸ”„ Flujo de Funcionamiento

```
Usuario envÃ­a mensaje
        â†“
Sistema intenta Bot Local
        â†“
Â¿Necesita IA?
        â†“
    SÃ­ â†’ Ollama (Principal)
        â†“
    Â¿Ollama responde?
        â†“
    No â†’ Groq (Fallback)
        â†“
    Respuesta al usuario
```

---

## ğŸ“ˆ MÃ©tricas Esperadas

### Con Ollama Principal:

| MÃ©trica | Valor |
|---------|-------|
| Tiempo respuesta | 2-8s |
| Costo por mensaje | $0.00 |
| LÃ­mite diario | Ilimitado |
| Calidad respuestas | 8/10 |
| Disponibilidad | 99%+ |

### Comparado con Groq:

| MÃ©trica | Ollama | Groq |
|---------|--------|------|
| Velocidad | ğŸŸ¡ 2-8s | ğŸŸ¢ 1-3s |
| Costo | ğŸŸ¢ $0 | ğŸŸ¢ $0 |
| LÃ­mites | ğŸŸ¢ Sin lÃ­mites | ğŸŸ¡ 30/min |
| Calidad | ğŸŸ¡ Buena | ğŸŸ¢ Excelente |

---

## ğŸ”§ Troubleshooting

### Problema: Ollama no responde
**SoluciÃ³n**: 
1. Verificar que el servidor estÃ© activo
2. Probar: `probar-ollama-easypanel.bat`
3. El sistema usarÃ¡ Groq automÃ¡ticamente

### Problema: Respuestas lentas
**SoluciÃ³n**:
1. Normal: 2-8 segundos
2. Si >10s, verificar servidor Ollama
3. Considerar volver a Groq como principal

### Problema: Respuestas de baja calidad
**SoluciÃ³n**:
1. Ajustar `AI_TEMPERATURE` (0.5-0.9)
2. Mejorar prompts del sistema
3. Considerar usar Groq para casos complejos

---

## ğŸš€ Volver a Groq como Principal

Si Ollama no funciona bien:

```bash
# Editar .env
AI_PROVIDER=groq
```

O usar:
```bash
copy .env.easypanel.optimizado .env
```

---

## ğŸ“ Notas Importantes

1. **Backup automÃ¡tico**: El script hace backup del `.env` actual
2. **Groq como fallback**: Siempre configurado por seguridad
3. **Sin lÃ­mites**: Ollama no tiene lÃ­mites de uso
4. **Velocidad aceptable**: 2-8s es razonable para la mayorÃ­a de casos
5. **Gratis**: No gastas en APIs externas

---

## âœ… Checklist de ActivaciÃ³n

- [ ] Ejecutar `ACTIVAR_OLLAMA_PRINCIPAL.bat`
- [ ] Editar `.env` con tus API keys de Groq
- [ ] Editar `.env` con tu `DATABASE_URL`
- [ ] Probar: `probar-ollama-easypanel.bat`
- [ ] Reiniciar servidor: `npm run dev`
- [ ] Probar bot por WhatsApp
- [ ] Monitorear velocidad y calidad

---

## ğŸ‰ Resultado Esperado

Con Ollama como principal:
- âœ… Sin lÃ­mites de tokens
- âœ… Costo $0
- âœ… Privacidad total
- âœ… Fallback a Groq si falla
- âš¡ Velocidad: 2-8 segundos (aceptable)
- ğŸ“Š Calidad: Buena (8/10)

---

**Listo para probar!** ğŸš€

Ejecuta: `ACTIVAR_OLLAMA_PRINCIPAL.bat`

# âœ… CONFIGURACIÃ“N OLLAMA EASYPANEL COMO BASE GRATUITA

## ðŸŽ¯ SISTEMA ACTUAL

**Ollama en EASYPANEL es la BASE PRINCIPAL (100% GRATIS)**
- Ollama corre en Easypanel (no local)
- Groq solo se usa como respaldo cuando Ollama falla
- Ahorro de costos: $0 en la mayorÃ­a de conversaciones
- Velocidad optimizada: 400 tokens mÃ¡ximo (respuestas rÃ¡pidas)

## ðŸ“‹ CONFIGURACIÃ“N ACTUAL (.env)

```env
# OLLAMA EN EASYPANEL - BASE PRINCIPAL (GRATIS) âœ…
USE_OLLAMA=true
OLLAMA_ENABLED=true
OLLAMA_BASE_URL=https://ollama-ollama.ginee6.easypanel.host
OLLAMA_MODEL=gemma2:2b
OLLAMA_TIMEOUT=15000
OLLAMA_MAX_TOKENS=400
LOCAL_RESPONSE_PRIORITY=true

# GROQ - SOLO RESPALDO
AI_PROVIDER=ollama
AI_FALLBACK_ORDER=ollama,groq,local
AI_FALLBACK_ENABLED=true
```

## ðŸš€ OPTIMIZACIONES PARA VELOCIDAD

### 1. Tokens Reducidos
- **Antes**: 800 tokens (20 segundos)
- **Ahora**: 400 tokens (5-8 segundos)
- **Resultado**: 60% mÃ¡s rÃ¡pido

### 2. Timeout Reducido
- **Antes**: 30 segundos
- **Ahora**: 15 segundos
- **Resultado**: Falla rÃ¡pido y usa Groq si hay problema

### 3. Modelo Optimizado
- **gemma2:2b**: Modelo pequeÃ±o y rÃ¡pido
- **Alternativa**: llama3.1:8b (mÃ¡s inteligente pero mÃ¡s lento)

## ðŸ”„ FLUJO DE RESPUESTA

```
1. Cliente envÃ­a mensaje
   â†“
2. Sistema intenta con OLLAMA (gratis)
   â†“
3. Si Ollama responde en <15s â†’ âœ… Usa Ollama
   â†“
4. Si Ollama falla o timeout â†’ ðŸ”„ Usa Groq (respaldo)
   â†“
5. Si Groq falla â†’ ðŸ“ Usa respuestas locales
```

## ðŸ’° AHORRO DE COSTOS

### Escenario Real (100 conversaciones/dÃ­a)

**CON OLLAMA COMO BASE:**
- 80% usa Ollama (gratis) = 80 conversaciones Ã— $0 = **$0**
- 20% usa Groq (respaldo) = 20 conversaciones Ã— $0.001 = **$0.02/dÃ­a**
- **Total mensual**: ~$0.60

**SIN OLLAMA (SOLO GROQ):**
- 100% usa Groq = 100 conversaciones Ã— $0.001 = **$0.10/dÃ­a**
- **Total mensual**: ~$3.00

**AHORRO: 80% de costos** ðŸ’°

## âš¡ CÃ“MO VERIFICAR QUE OLLAMA FUNCIONA

### 1. Verificar que Ollama de Easypanel estÃ¡ corriendo
```bash
# Windows
curl https://ollama-ollama.ginee6.easypanel.host/api/tags

# Debe responder con lista de modelos
```

### 2. Probar el bot
```bash
node test-ollama-completo.js
```

### 3. Ver logs en tiempo real
```bash
npm run dev
```

Busca en los logs:
- âœ… `[Ollama] Respuesta generada` = Ollama funcionando
- ðŸ”„ `[Fallback] Usando Groq` = Ollama fallÃ³, usando respaldo

## ðŸ› ï¸ COMANDOS ÃšTILES

### Verificar Ollama de Easypanel
```bash
curl https://ollama-ollama.ginee6.easypanel.host/api/tags
```

### Probar Ollama directamente
```bash
curl https://ollama-ollama.ginee6.easypanel.host/api/generate -d '{
  "model": "gemma2:2b",
  "prompt": "Hola, Â¿cÃ³mo estÃ¡s?",
  "stream": false
}'
```

**NOTA**: Ollama corre en Easypanel, no necesitas instalarlo localmente

## ðŸŽ¨ FORMATO DE RESPUESTAS

El sistema usa el nuevo formato profesional:
- âŒ NO asteriscos (*)
- âŒ NO puntos (...)
- âœ… Emojis profesionales
- âœ… Espaciado elegante
- âœ… Formato tipo boleta/card

## ðŸ“Š MÃ‰TRICAS DE RENDIMIENTO

### Ollama gemma2:2b
- **Velocidad**: 5-8 segundos
- **Calidad**: Buena para ventas
- **Costo**: $0 (gratis)
- **Uso recomendado**: 80% de conversaciones

### Groq llama-3.1-8b-instant
- **Velocidad**: 2-3 segundos
- **Calidad**: Excelente
- **Costo**: ~$0.001 por conversaciÃ³n
- **Uso recomendado**: 20% (respaldo)

## ðŸ”§ TROUBLESHOOTING

### Problema: "Ollama no responde"
**SoluciÃ³n:**
```bash
# 1. Verificar que Ollama de Easypanel estÃ¡ corriendo
curl https://ollama-ollama.ginee6.easypanel.host/api/tags

# 2. Si no responde, verificar en Easypanel que el servicio estÃ¡ activo
# 3. Reiniciar el bot
npm run dev
```

**NOTA**: Ollama corre en Easypanel, no local. Si no responde, verifica el servicio en Easypanel.

### Problema: "Respuestas muy lentas"
**SoluciÃ³n:**
- Reducir `OLLAMA_MAX_TOKENS` a 300
- Cambiar a modelo mÃ¡s pequeÃ±o: `gemma2:2b`
- Verificar que no hay otros procesos usando CPU

### Problema: "Ollama inventa informaciÃ³n"
**SoluciÃ³n:**
- El sistema `RealDataEnforcer` previene esto
- Siempre consulta la BD antes de responder
- Si persiste, aumentar `OLLAMA_TEMPERATURE` a 0.5

## âœ… CHECKLIST DE VERIFICACIÃ“N

- [ ] Ollama de Easypanel estÃ¡ activo (`curl https://ollama-ollama.ginee6.easypanel.host/api/tags`)
- [ ] `.env` tiene `USE_OLLAMA=true`
- [ ] `.env` tiene `OLLAMA_ENABLED=true`
- [ ] `.env` tiene `OLLAMA_BASE_URL=https://ollama-ollama.ginee6.easypanel.host`
- [ ] `.env` tiene `LOCAL_RESPONSE_PRIORITY=true`
- [ ] Bot responde en 5-8 segundos
- [ ] Formato sin asteriscos
- [ ] Fotos se envÃ­an automÃ¡ticamente

**NOTA**: Ollama corre en Easypanel, no necesitas instalarlo localmente

## ðŸŽ¯ PRÃ“XIMOS PASOS

1. **Reiniciar el servidor** para aplicar cambios
   ```bash
   # Ctrl+C para detener
   npm run dev
   ```

2. **Probar bÃºsqueda de idiomas**
   ```bash
   node test-busqueda-idiomas.js
   ```

3. **Verificar formato profesional**
   - NO debe tener asteriscos
   - Debe usar emojis
   - Debe mostrar megapacks si no encuentra curso

## ðŸ“ NOTAS IMPORTANTES

- Ollama es **100% gratis** y corre en **Easypanel** (no local)
- Groq es **respaldo** para cuando Ollama falla
- El sistema **automÃ¡ticamente** cambia entre proveedores
- **No necesitas instalar Ollama localmente**, ya estÃ¡ en Easypanel
- El ahorro de costos es **significativo** (80%)

---

**Ãšltima actualizaciÃ³n**: 13 Diciembre 2025
**Estado**: âœ… Ollama activado como base principal
**Ahorro**: 80% de costos vs solo Groq

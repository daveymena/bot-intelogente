# ğŸš€ REFERENCIA RÃPIDA: OLLAMA LLAMA3.1:8B

## âš¡ Inicio RÃ¡pido

```bash
# Iniciar sistema
INICIAR_CON_OLLAMA_LLAMA31.bat

# O manualmente
npm run dev
```

## ğŸ”§ ConfiguraciÃ³n Actual

```env
OLLAMA_MODEL=llama3.1:8b
DISABLE_GROQ=true
AI_FALLBACK_ENABLED=false
```

## ğŸ“Š MÃ©tricas

- **Velocidad:** 15-20 segundos
- **Confianza:** 80-95%
- **Costo:** $0 (gratis)
- **Memoria:** 8 mensajes de contexto

## ğŸ§ª Tests RÃ¡pidos

```bash
# Test simple (3 casos)
npx tsx scripts/test-ollama-simple-contexto.ts

# Test completo (7 casos)
npx tsx scripts/test-ollama-con-productos-reales.ts

# Debug productos
npx tsx scripts/test-busqueda-productos-debug.ts
```

## ğŸ” Verificar Ollama

```bash
# Ver modelos disponibles
curl https://davey-ollama2.mapf5v.easypanel.host/api/tags

# Probar modelo
curl -X POST https://davey-ollama2.mapf5v.easypanel.host/api/generate ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"llama3.1:8b\",\"prompt\":\"Hola\",\"stream\":false}"
```

## ğŸ“ Logs Ãštiles

```bash
# Ver logs del orchestrator
[Orchestrator] ğŸ¯ Iniciando procesamiento...
[Orchestrator] ğŸ¤– Usando Ollama...
[Ollama] ğŸ” Productos encontrados: 5
[Ollama] ğŸ“¦ Productos:
[Ollama]    1. Laptop Asus - $1.329.900
[Orchestrator] âœ… Ollama respondiÃ³ con confianza 95%
```

## âš ï¸ Troubleshooting

### Problema: "Ollama timeout"
```bash
# Aumentar timeout en .env
OLLAMA_TIMEOUT=120000  # 2 minutos
```

### Problema: "No encuentra productos"
```bash
# Verificar userId
npx tsx scripts/test-busqueda-productos-debug.ts
```

### Problema: "Respuestas muy largas"
```bash
# Reducir tokens en .env
OLLAMA_MAX_TOKENS=300
```

### Problema: "Pierde contexto"
```typescript
// Aumentar historial en ollama-orchestrator-professional.ts
...history.slice(-10)  // 10 mensajes en lugar de 8
```

## ğŸ¯ Casos de Uso

### âœ… Funciona Bien:
- Saludos
- BÃºsqueda de productos
- Preguntas por "opciÃ³n 2"
- Objeciones de precio
- Mantener contexto

### âš ï¸ Mejorable:
- DetecciÃ³n de mÃ©todos de pago
- GeneraciÃ³n de links
- Nombres de productos muy largos

## ğŸ“ Comandos Ãštiles

```bash
# Reiniciar Ollama en Easypanel
docker restart ollama-container

# Ver logs de Ollama
docker logs ollama-container -f

# Descargar modelo nuevo
docker exec ollama-container ollama pull llama3.1:8b

# Listar modelos
docker exec ollama-container ollama list

# Eliminar modelo
docker exec ollama-container ollama rm llama3.2:3b
```

## ğŸ”„ Cambiar de Modelo

### A llama3.2:3b (mÃ¡s rÃ¡pido, menos memoria)
```env
OLLAMA_MODEL=llama3.2:3b
```

### A gemma2:2b (muy rÃ¡pido, menos preciso)
```env
OLLAMA_MODEL=gemma2:2b
```

### Volver a Groq (mÃ¡s rÃ¡pido, con costo)
```env
DISABLE_GROQ=false
AI_FALLBACK_ENABLED=true
AI_FALLBACK_ORDER=groq,ollama,local
```

## ğŸ“ˆ Monitoreo

### Ver estadÃ­sticas
```typescript
const stats = await OllamaProfessionalOrchestrator.getStats()
console.log(stats)
```

### Verificar disponibilidad
```typescript
const available = await OllamaProfessionalOrchestrator.isAvailable()
console.log('Ollama disponible:', available)
```

## ğŸ‰ Estado Actual

âœ… **FUNCIONANDO EN PRODUCCIÃ“N**
- Modelo: llama3.1:8b
- Velocidad: 15-20s
- Confianza: 80-95%
- Costo: $0
- Memoria: 8 mensajes

---

**Ãšltima actualizaciÃ³n:** 28 Noviembre 2025  
**PrÃ³xima revisiÃ³n:** 5 Diciembre 2025
